// Production Telegram Bot Webhook Handler
import { Handler, HandlerContext, HandlerEvent } from '@netlify/functions';
import { Bot, InputFile, webhookCallback, InlineKeyboard } from 'grammy';

// Constants
const CLAUDE_MODEL = 'claude-3-5-sonnet-20241022';
const IMAGEN_MODEL = 'imagen-4.0-generate-001';
const ANTHROPIC_VERSION = '2023-06-01';

// Gemini Files API Configuration
const FILES_API_THRESHOLD = 15 * 1024 * 1024; // 15MB threshold for Files API
const GEMINI_MODELS = {
  IMAGE_PREVIEW: 'gemini-2.5-flash-image-preview',
  FLASH_EXP: 'gemini-2.0-flash-exp',
  FLASH: 'gemini-1.5-flash'
} as const;

// Import prompt management utilities
import { getImagePrompt, getDobbyImagePrompt, getQAPrompt, getSystemMessage } from '../../src/utils/prompt-manager';

// Import tracking system
import { parseTrackingCommand, handleTrackingCommand, trackMessageMiddleware } from '../../src/utils/tracking-commands';

// Import error handling
import { ensureChatGroupExists, getUserFriendlyErrorMessage, logErrorWithContext } from '../../src/utils/error-handler';
import { TrackingError } from '../../src/types/tracking.types';

// Import version management
import { getVersionInfoForHelp, getFormattedVersionHistory } from '../../src/utils/version-manager';

// Import image editing handlers
import { registerImageEditHandlers } from '../../src/handlers/image-edit-handler';
import { handlePhotoUpload } from '../../src/handlers/photo-upload-handler';

// Import Replicate service
import { replicateService } from '../../src/services/replicate-service';

// Import Supabase
import { supabase } from '../../src/utils/supabase';

// Environment variables - support both Netlify and Render naming
const BOT_TOKEN = process.env.BOT_TOKEN || process.env.TELEGRAM_BOT_TOKEN || '';
const CLAUDE_API_KEY = process.env.CLAUDE_API_KEY || '';
const GOOGLE_API_KEY = process.env.GOOGLE_API_KEY || '';

// =============================================================================
// COST CALCULATION FUNCTIONS
// =============================================================================

/**
 * Calculate cost for Claude API usage
 * Pricing: ~$3 per million input tokens, ~$15 per million output tokens
 */
function calculateClaudeCost(inputTokens: number, outputTokens: number): number {
  const INPUT_COST_PER_MILLION = 3.0;
  const OUTPUT_COST_PER_MILLION = 15.0;

  const inputCost = (inputTokens / 1000000) * INPUT_COST_PER_MILLION;
  const outputCost = (outputTokens / 1000000) * OUTPUT_COST_PER_MILLION;

  return inputCost + outputCost;
}

/**
 * Calculate cost for Google Imagen API usage
 * Pricing: ~$0.020 per image
 */
function calculateImagenCost(): number {
  return 0.020;
}

/**
 * Calculate cost for Gemini Vision API usage
 * Pricing: ~$0.00025 per image analysis
 */
function calculateGeminiVisionCost(): number {
  return 0.00025;
}

/**
 * Calculate cost for Gemini Files API usage
 * Pricing: ~$0.0005 per image upload + processing cost
 */
function calculateGeminiFilesCost(): number {
  return 0.0005;
}

/**
 * Format cost display for users
 */
function formatCost(cost: number): string {
  if (cost < 0.001) {
    return '< $0.001';
  }
  return `$${cost.toFixed(3)}`;
}

// =============================================================================
// GEMINI FILES API INTEGRATION
// =============================================================================

/**
 * Upload image to Gemini Files API for processing large images (>15MB)
 * @param imageBuffer - Buffer containing image data
 * @param mimeType - MIME type of the image (e.g., 'image/jpeg')
 * @returns Promise resolving to file upload response
 */
async function uploadToGeminiFiles(imageBuffer: Buffer, mimeType: string): Promise<{uri: string, name: string}> {
  console.log(`ğŸ“¤ Uploading image to Gemini Files API (${imageBuffer.length} bytes, ${mimeType})`);

  const startTime = Date.now();

  try {
    // Create multipart form data
    const formData = new FormData();

    // Add metadata
    formData.append('metadata', JSON.stringify({
      file: {
        displayName: `telegram_image_${Date.now()}`
      }
    }));

    // Add the image file
    const blob = new Blob([imageBuffer], { type: mimeType });
    formData.append('file', blob);

    const response = await fetchWithTimeout(
      `https://generativelanguage.googleapis.com/upload/v1beta/files?key=${GOOGLE_API_KEY}`,
      {
        method: 'POST',
        body: formData
      },
      30000 // 30-second timeout for upload
    );

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Files API upload failed: ${response.status} - ${errorText}`);
    }

    const fileData = await response.json();
    const uploadTime = Date.now() - startTime;

    console.log(`âœ… File uploaded successfully in ${uploadTime}ms:`, {
      uri: (fileData as any).file?.uri,
      name: (fileData as any).file?.name,
      size: imageBuffer.length
    });

    return {
      uri: (fileData as any).file?.uri,
      name: (fileData as any).file?.name
    };
  } catch (error) {
    console.error('âŒ Gemini Files API upload error:', error);
    throw error;
  }
}

/**
 * Delete file from Gemini Files API after processing
 * @param fileUri - URI of the file to delete
 */
async function deleteGeminiFile(fileUri: string): Promise<void> {
  try {
    console.log(`ğŸ—‘ï¸ Cleaning up Gemini file: ${fileUri}`);

    const response = await fetchWithTimeout(
      `${fileUri}?key=${GOOGLE_API_KEY}`,
      {
        method: 'DELETE'
      },
      10000 // 10-second timeout for deletion
    );

    if (response.ok) {
      console.log(`âœ… File deleted successfully: ${fileUri}`);
    } else {
      console.warn(`âš ï¸ File deletion failed (${response.status}), but continuing...`);
    }
  } catch (error) {
    console.warn('âš ï¸ File cleanup failed (but continuing):', error);
    // Don't throw - cleanup failure shouldn't stop the main flow
  }
}

/**
 * Process image using Gemini Files API with file URI
 * @param fileUri - URI of the uploaded file
 * @param editRequest - The editing request from user
 * @param modelName - Gemini model to use
 * @returns Promise resolving to API response
 */
async function processImageWithFilesAPI(
  fileUri: string,
  editRequest: string,
  modelName: string
): Promise<Response> {
  console.log(`ğŸ”„ Processing image with Files API using ${modelName}`);

  const requestBody = {
    contents: [{
      parts: [
        {
          text: modelName.includes('2.5-flash-image-preview')
            ? `Generate an edited version of this image with the following modification: ${editRequest}

Important: You must return the edited image itself, not a text description.
Apply the requested changes directly to the image while preserving the original subjects and composition.
Output: Modified image with the requested changes applied.`
            : `You are an image editor. Edit this image based on: "${editRequest}"

Modify the image to fulfill this request while maintaining the original subjects and composition.
Apply the specific changes requested.`
        },
        {
          fileData: {
            mimeType: "image/jpeg",
            fileUri: fileUri
          }
        }
      ]
    }],
    generationConfig: {
      temperature: 0.4,
      maxOutputTokens: 8192
    }
  };

  return await fetchWithTimeout(
    `https://generativelanguage.googleapis.com/v1beta/models/${modelName}:generateContent?key=${GOOGLE_API_KEY}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(requestBody)
    },
    30000 // 30-second timeout
  );
}

// =============================================================================
// ENHANCED FETCH WITH TIMEOUT
// =============================================================================

/**
 * Enhanced fetch with timeout support
 */
async function fetchWithTimeout(
  url: string,
  options: RequestInit,
  timeoutMs: number = 30000
): Promise<Response> {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });
    clearTimeout(timeoutId);
    return response;
  } catch (error) {
    clearTimeout(timeoutId);
    if (error instanceof Error && error.name === 'AbortError') {
      throw new Error(`Request timed out after ${timeoutMs}ms`);
    }
    throw error;
  }
}

// Create bot instance with validation
if (!BOT_TOKEN) {
  console.error('âŒ BOT_TOKEN is not set!');
  console.error('Available env vars:', Object.keys(process.env).filter(k => !k.includes('KEY')));
}

const bot = new Bot(BOT_TOKEN || 'dummy-token-for-build');

// =============================================================================
// CONVERSATION CONTEXT MANAGEMENT
// =============================================================================

// In-memory conversation context for session continuity
interface ConversationMessage {
  role: 'user' | 'assistant';
  content: string;
  timestamp: number;
}

interface ConversationContext {
  messages: ConversationMessage[];
  lastActive: number;
}

const conversationContexts = new Map<string, ConversationContext>();
const CONTEXT_MAX_MESSAGES = 10; // Keep last 10 messages (5 exchanges)
const CONTEXT_TTL = 30 * 60 * 1000; // 30 minutes

// Cleanup old contexts periodically
setInterval(() => {
  const now = Date.now();
  conversationContexts.forEach((context, key) => {
    if (now - context.lastActive > CONTEXT_TTL) {
      conversationContexts.delete(key);
      console.log(`ğŸ§¹ Cleaned up conversation context for ${key}`);
    }
  });
}, 5 * 60 * 1000); // Check every 5 minutes

/**
 * Get or create conversation context for a user
 */
function getConversationContext(userId: number, chatId: number): ConversationContext {
  const key = `${userId}:${chatId}`;
  let context = conversationContexts.get(key);

  if (!context) {
    context = {
      messages: [],
      lastActive: Date.now()
    };
    conversationContexts.set(key, context);
    console.log(`âœ¨ Created new conversation context for user ${userId} in chat ${chatId}`);
  }

  return context;
}

/**
 * Add message to conversation context
 */
function addToContext(userId: number, chatId: number, role: 'user' | 'assistant', content: string): void {
  const context = getConversationContext(userId, chatId);

  context.messages.push({
    role,
    content,
    timestamp: Date.now()
  });

  // Keep only last N messages
  if (context.messages.length > CONTEXT_MAX_MESSAGES) {
    context.messages = context.messages.slice(-CONTEXT_MAX_MESSAGES);
  }

  context.lastActive = Date.now();

  console.log(`ğŸ“ Added ${role} message to context. Total messages: ${context.messages.length}`);
}

/**
 * Get conversation history for Claude API
 */
function getContextMessages(userId: number, chatId: number): Array<{role: string, content: string}> {
  const context = getConversationContext(userId, chatId);
  return context.messages.map(msg => ({
    role: msg.role,
    content: msg.content
  }));
}

// =============================================================================
// DUPLICATE MESSAGE PREVENTION
// =============================================================================

// In-memory cache to prevent duplicate message processing
const processedMessages = new Set<string>();
const CACHE_CLEANUP_INTERVAL = 5 * 60 * 1000; // 5 minutes
const MESSAGE_CACHE_TTL = 10 * 60 * 1000; // 10 minutes

// Cleanup old message IDs periodically
setInterval(() => {
  const now = Date.now();
  processedMessages.forEach((messageKey) => {
    const [timestamp] = messageKey.split(':');
    if (now - parseInt(timestamp) > MESSAGE_CACHE_TTL) {
      processedMessages.delete(messageKey);
    }
  });
}, CACHE_CLEANUP_INTERVAL);

// Middleware to prevent duplicate processing
bot.use(async (ctx, next) => {
  const message = ctx.message;
  if (!message) return next();
  
  // Create unique message key: timestamp:chat_id:message_id:user_id
  const messageKey = `${Date.now()}:${ctx.chat.id}:${message.message_id}:${ctx.from?.id}`;
  const checkKey = `${ctx.chat.id}:${message.message_id}:${ctx.from?.id}`;
  
  // Check if we've already processed this message
  const alreadyProcessed = Array.from(processedMessages).some(key => key.includes(checkKey));
  
  if (alreadyProcessed) {
    console.log(`ğŸ”„ Duplicate message detected, skipping: ${checkKey}`);
    return; // Skip duplicate processing
  }
  
  // Mark message as being processed
  processedMessages.add(messageKey);
  console.log(`âœ… Processing new message: ${checkKey}`);
  
  return next();
});

// Add tracking middleware to track messages when tracking is active
bot.use(trackMessageMiddleware);

// Error handling middleware
bot.use(async (ctx, next) => {
  try {
    // Ensure chat group exists in database
    await ensureChatGroupExists(ctx);
    await next();
  } catch (error) {
    console.error('Bot middleware error:', error);
    logErrorWithContext(error as Error, {
      chat_id: ctx.chat?.id,
      user_id: ctx.from?.id,
      message_text: ctx.message && 'text' in ctx.message ? ctx.message.text : null

    });
    
    if (error instanceof TrackingError) {
      await ctx.reply(getUserFriendlyErrorMessage(error));
    } else {
      await ctx.reply(`ğŸ§™â€â™€ï¸ **ë„ë¹„ê°€ ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œë¥¼ ë§Œë‚¬ìŠµë‹ˆë‹¤...**

âŒ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ğŸ’¡ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.`);
    }
  }
});

// Helper function to generate image with Imagen
async function generateImageWithImagen(userInput: string, isDobby: boolean = false, userId?: string, chatId?: string) {
  const startTime = Date.now();

  try {
    console.log(`ğŸ¨ Generating image with Imagen for: "${userInput}"`);

    // Get dynamic prompt from database
    const enhancedPrompt = isDobby
      ? await getDobbyImagePrompt(userInput)
      : await getImagePrompt(userInput);

    console.log(`ğŸ“ Using enhanced prompt: "${enhancedPrompt}"`);

    // Use reduced timeout to fit within Netlify's 10-second limit
    // Reduce image size for faster generation
    const response = await fetchWithTimeout(
      'https://generativelanguage.googleapis.com/v1beta/models/imagen-4.0-generate-001:predict',
      {
        method: 'POST',
        headers: {
          'x-goog-api-key': GOOGLE_API_KEY,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          instances: [{ prompt: enhancedPrompt }],
          parameters: {
            sampleCount: 1,
            sampleImageSize: '1K',  // Imagen 4.0 requires 1K or 2K
            aspectRatio: '1:1'
          }
        })
      },
      20000 // 20-second timeout for Render.com (30-second limit)
    );

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Imagen API error: ${response.status} ${response.statusText} - ${errorText}`);
    }

    const data = await response.json();
    const processingTime = Date.now() - startTime;

    console.log(`ğŸ¨ Image generation successful in ${processingTime}ms!`);

    // Calculate cost
    const imageCost = calculateImagenCost();

    if ((data as any).predictions && (data as any).predictions.length > 0) {
      const prediction = (data as any).predictions[0];
      if (prediction.bytesBase64Encoded) {
        return {
          imageData: prediction.bytesBase64Encoded,
          mimeType: prediction.mimeType || 'image/png',
          cost: imageCost,
          processingTime
        };
      }
    }

    throw new Error('No image data in response');
  } catch (error) {
    console.error('Imagen API error:', error);
    throw error;
  }
}

// Helper function for Claude API with dynamic prompts and conversation context
async function callClaudeAPI(
  message: string,
  maxTokens: number = 2000,
  temperature: number = 0.7,
  conversationHistory: Array<{role: string, content: string}> = []
) {
  const startTime = Date.now();

  try {
    // Build messages array with conversation history
    const messages: Array<{role: string, content: string}> = [];

    // Add conversation history
    if (conversationHistory.length > 0) {
      messages.push(...conversationHistory);
      console.log(`ğŸ’¬ Including ${conversationHistory.length} previous messages for context`);
    }

    // Add current message
    messages.push({
      role: 'user',
      content: message
    });

    // Use enhanced fetch with timeout
    const response = await fetchWithTimeout(
      'https://api.anthropic.com/v1/messages',
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': CLAUDE_API_KEY,
          'anthropic-version': '2023-06-01'
        },
        body: JSON.stringify({
          model: 'claude-3-5-sonnet-20241022',
          max_tokens: maxTokens,
          temperature: temperature,
          messages: messages
        })
      },
      45000 // 45-second timeout for Claude API (increased from 20s due to timeouts)
    );


    const data = await response.json();
    const processingTime = Date.now() - startTime;

    if (response.ok) {
      const responseText = (data as any).content[0]?.text || 'ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.';

      // Calculate cost based on token usage
      const usage = (data as any).usage;
      const inputTokens = usage?.input_tokens || 0;
      const outputTokens = usage?.output_tokens || 0;
      const cost = calculateClaudeCost(inputTokens, outputTokens);

      return {
        text: responseText,
        cost,
        processingTime,
        inputTokens,
        outputTokens
      };
    } else {
      const errorText = await response.text();
      console.error('Claude API Error Response:', errorText);
      throw new Error((data as any).error?.message || `ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: ${response.status} ${response.statusText}`);
    }
  } catch (error) {
    console.error('Claude API Error:', error);
    throw error;
  }
}

// Helper function for Claude API (Vision) with retry logic
async function callClaudeVisionAPI(prompt: string, imageData: string, mediaType: string, retries: number = 2) {
  for (let attempt = 0; attempt <= retries; attempt++) {
    try {
      if (attempt > 0) {
        console.log(`ğŸ”„ Retrying Claude Vision API (attempt ${attempt + 1}/${retries + 1})...`);
        // Wait before retry (exponential backoff)
        await new Promise(resolve => setTimeout(resolve, Math.pow(2, attempt) * 1000));
      }

      console.log(`ğŸ–¼ï¸ Calling Claude Vision API for prompt: "${prompt}"`);
      const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': CLAUDE_API_KEY,
        'anthropic-version': ANTHROPIC_VERSION
      },
      body: JSON.stringify({
        model: CLAUDE_MODEL,
        max_tokens: 2000,
        messages: [{
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: imageData,
              },
            },
            {
              type: 'text',
              text: prompt
            }
          ]
        }]
      })
    });

      if (response.ok) {
        const data = await response.json();
        console.log('ğŸ–¼ï¸ Claude Vision API call successful!');
        return (data as any).content[0]?.text || 'ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.';
      } else {
        // Try to parse error response
        let errorMessage = `Vision API ì˜¤ë¥˜: ${response.status} ${response.statusText}`;
        let isOverloaded = false;
        try {
          const errorData = await response.json();
          console.error('Claude Vision API Error Response:', errorData);
          errorMessage = (errorData as any).error?.message || errorMessage;
          // Check if it's an overload error
          isOverloaded = (errorData as any).error?.type === 'overloaded_error' ||
                        errorMessage.toLowerCase().includes('overloaded');
        } catch {
          // If JSON parsing fails, use default error message
          console.error('Could not parse error response body');
        }

        // If it's an overload error and we have retries left, throw to retry
        if (isOverloaded && attempt < retries) {
          console.log('ğŸ”„ Claude API is overloaded, will retry...');
          throw new Error(errorMessage);
        } else {
          // Final error, no more retries
          throw new Error(errorMessage);
        }
      }
    } catch (error) {
      console.error(`Claude Vision API Error (attempt ${attempt + 1}):`, error);

      // If this is the last attempt, throw the error
      if (attempt === retries) {
        throw error;
      }
      // Otherwise, continue to next iteration for retry
    }
  }

  // Should not reach here, but just in case
  throw new Error('Claude Vision API failed after all retries');
}

// Centralized error handler
async function handleError(ctx: any, error: Error, command: string, thinkingMessage: any = null) {
  console.error(`Error in ${command}:`, error);

  const errorMessage = `âŒ **'${command}' ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ**

**ì˜¤ë¥˜ ë‚´ìš©:**
${error.message}

ğŸ’¡ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì‹œê±°ë‚˜, ë¬¸ì œê°€ ê³„ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.`;

  try {
    if (thinkingMessage?.message_id) {
      await ctx.api.editMessageText(
        ctx.chat.id,
        thinkingMessage.message_id,
        errorMessage
      );
    } else {
      await ctx.reply(errorMessage);
    }
  } catch (replyError) {
    console.error('Failed to send error message to user:', replyError);
  }
}

// Helper function to detect questions
function isQuestion(text: string): boolean {
  const questionPatterns = [
    /\?$/,                    // ends with ?
    /^(ë­|ë¬´ì—‡|ì–´ë–»|ì–´ë””|ì–¸ì œ|ì™œ|ëˆ„êµ¬|ì–´ëŠ)/,  // Korean question words
    /^(what|how|where|when|why|who|which)/i,  // English question words
    /(ë°©ë²•|ì–´ë–»ê²Œ|ì•Œë ¤ì¤˜|ê¶ê¸ˆ)/,    // asking for help/info
    /(ì¶”ì²œ|ì œì•ˆ|ì˜ê²¬)/,           // asking for recommendations
  ];

  return questionPatterns.some(pattern => pattern.test(text.trim()));
}

// Helper function to detect Dobby activation
function isDobbyActivated(text: string, isReply: boolean = false): { activated: boolean; command: string | null; content: string } {
  const dobbyPattern = /ë„ë¹„ì•¼[,\s]*(.*)/i;
  const match = text.match(dobbyPattern);

  if (!match) {
    return { activated: false, command: null, content: '' };
  }

  const content = match[1].trim();

  // If it's a reply to a photo, default to edit command
  if (isReply) {
    return { activated: true, command: 'edit', content: content };
  }

  // Check for help commands
  if (/(ì‚¬ìš©ë²•|ë„ì›€ë§|ì‚¬ìš©ë°©ë²•|ë©”ë‰´ì–¼|ê°€ì´ë“œ|ëª…ë ¹ì–´ ì•Œë ¤|ë„ì›€ ì¤˜|help)/i.test(content)) {
    return { activated: true, command: 'help', content: content };
  }

  // Check for image generation commands
  if (/(ê·¸ë ¤ì¤˜|ê·¸ë ¤|ê·¸ë¦¼|ì´ë¯¸ì§€|ìƒì„±)/i.test(content)) {
    // Remove only the final command words, not all occurrences
    const imagePrompt = content
      .replace(/\s*(ê·¸ë¦¼ì„\s+)?ê·¸ë ¤ì¤˜\s*$/i, '')  // Remove "ê·¸ë¦¼ì„ ê·¸ë ¤ì¤˜" at the end
      .replace(/\s*ê·¸ë ¤ì¤˜\s*$/i, '')  // Remove "ê·¸ë ¤ì¤˜" at the end
      .replace(/\s*ê·¸ë ¤\s*$/i, '')  // Remove "ê·¸ë ¤" at the end
      .replace(/\s*ë§Œë“¤ì–´ì¤˜\s*$/i, '')  // Remove "ë§Œë“¤ì–´ì¤˜" at the end
      .replace(/\s*ìƒì„±í•´ì¤˜\s*$/i, '')  // Remove "ìƒì„±í•´ì¤˜" at the end
      .trim();
    return { activated: true, command: 'image', content: imagePrompt };
  }

  // Check for Q&A commands
  if (/(ì•Œë ¤ì¤˜|ë­ì•¼|ì„¤ëª…í•´|ê°€ë¥´ì³|ê¶ê¸ˆ)/i.test(content)) {
    return { activated: true, command: 'ask', content: content };
  }

  // Default to Q&A if no specific command detected
  return { activated: true, command: 'ask', content: content };
}

// Enhanced Q&A function with dynamic prompts and conversation context
async function answerQuestion(question: string, isDobby: boolean = false, userId?: string, chatId?: string) {
  try {
    console.log(`ğŸ¤” Processing question: "${question}"`);

    // Get dynamic prompt from database
    const { prompt, maxTokens, temperature } = await getQAPrompt(question, isDobby);

    console.log(`ğŸ“ Using ${isDobby ? 'Dobby' : 'standard'} prompt template`);

    // Get conversation context if userId and chatId are provided
    let conversationHistory: Array<{role: string, content: string}> = [];
    if (userId && chatId) {
      const userIdNum = parseInt(userId);
      const chatIdNum = parseInt(chatId);
      conversationHistory = getContextMessages(userIdNum, chatIdNum);

      if (conversationHistory.length > 0) {
        console.log(`ğŸ”„ Continuing conversation with ${conversationHistory.length} previous messages`);
      }
    }

    const claudeResponse = await callClaudeAPI(prompt, maxTokens, temperature, conversationHistory);

    // Store the conversation in context
    if (userId && chatId) {
      const userIdNum = parseInt(userId);
      const chatIdNum = parseInt(chatId);
      addToContext(userIdNum, chatIdNum, 'user', question);
      addToContext(userIdNum, chatIdNum, 'assistant', claudeResponse.text);
    }

    return {
      text: claudeResponse.text,
      cost: claudeResponse.cost,
      processingTime: claudeResponse.processingTime,
      tokenUsage: {
        input: claudeResponse.inputTokens,
        output: claudeResponse.outputTokens
      }
    };
  } catch (error) {
    console.error('Q&A Error:', error);
    throw error;
  }
}

// Helper function to get help message content
async function getHelpMessage(): Promise<string> {
  try {
    const versionInfo = await getVersionInfoForHelp();

    return `ğŸ§™â€â™€ï¸ **ë„ë¹„ AI ë´‡ì…ë‹ˆë‹¤!** ğŸ 

${versionInfo}

ğŸŒŸ **ë„ë¹„ ê°œì¸ë¹„ì„œ ëª¨ë“œ:**
â€¢ ğŸ¨ **"ë„ë¹„ì•¼, ~~~ ê·¸ë ¤ì¤˜"** - ë§ˆë²•ê°™ì€ ì´ë¯¸ì§€ ìƒì„±
â€¢ ğŸ’¬ **"ë„ë¹„ì•¼, ~~~ ì•Œë ¤ì¤˜/ë­ì•¼?"** - ì¶©ì‹¤í•œ ì§ˆë¬¸ ë‹µë³€
â€¢ ğŸ–¼ï¸ **ì‚¬ì§„ì— ë‹µì¥** - ì´ë¯¸ì§€ í¸ì§‘ ë° ìˆ˜ì •

ğŸ“ **NEW! ëŒ€í™” ì¶”ì  ë° ìš”ì•½ ê¸°ëŠ¥:**
â€¢ **"ë„ë¹„ì•¼, ëŒ€í™” ì¶”ì  ì‹œì‘í•´ì¤˜"** - ì¤‘ìš”í•œ ëŒ€í™” ê¸°ë¡ ì‹œì‘
â€¢ **"ë„ë¹„ì•¼, ëŒ€í™” ì¶”ì  ê·¸ë§Œí•´ì¤˜"** - ì¶”ì  ì¤‘ë‹¨
â€¢ **"ë„ë¹„ì•¼, ìš”ì•½í•´ì¤˜"** - ì¶”ì ëœ ëŒ€í™”ë¥¼ ë˜‘ë˜‘í•˜ê²Œ ìš”ì•½
â€¢ ğŸ“Š ê°œì¸ë³„ ì¶”ì  - ê°ì ì›í•˜ëŠ” ëŒ€ë¡œ ì¶”ì  ê°€ëŠ¥

ğŸ¤– **ì¼ë°˜ AI ê¸°ëŠ¥:**
â€¢ /ask [ì§ˆë¬¸] - ëª…ì‹œì  ì§ˆë¬¸í•˜ê¸°
â€¢ /image [ì„¤ëª…] - ì´ë¯¸ì§€ ìƒì„±
â€¢ /help - ì‚¬ìš©ë²• ë³´ê¸°
â€¢ /version - ë²„ì „ ê¸°ë¡ í™•ì¸
â€¢ ìë™ ì§ˆë¬¸ ê°ì§€ - ì§ˆë¬¸í•˜ë©´ ë°”ë¡œ ë‹µë³€

ğŸ¯ **ì¶”ì  ì‹œìŠ¤í…œ ëª…ë ¹ì–´:**
â€¢ /track_start - ëŒ€í™” ì¶”ì  ì‹œì‘
â€¢ /track_stop - ëŒ€í™” ì¶”ì  ì¤‘ë‹¨
â€¢ /summarize - ëŒ€í™” ìš”ì•½ ìƒì„±
â€¢ /track_status - í˜„ì¬ ì¶”ì  ìƒíƒœ í™•ì¸

ğŸ§™â€â™€ï¸ **ë„ë¹„ ì‚¬ìš© ì˜ˆì‹œ:**
â€¢ "ë„ë¹„ì•¼, ê·€ì—¬ìš´ ê°•ì•„ì§€ ê·¸ë ¤ì¤˜"
â€¢ "ë„ë¹„ì•¼, íŒŒì´ì¬ ê³µë¶€ë²• ì•Œë ¤ì¤˜"
â€¢ "ë„ë¹„ì•¼, ëŒ€í™” ì¶”ì  ì‹œì‘í•´ì¤˜"
â€¢ "ë„ë¹„ì•¼, ìš”ì•½í•´ì¤˜"
â€¢ "ë„ë¹„ì•¼, ì‚¬ìš©ë²• ì•Œë ¤ì¤˜"

âœ¨ **ë„ë¹„ì˜ íŠ¹ë³„í•¨:**
â€¢ ğŸ­ í•´ë¦¬í¬í„° ë„ë¹„ ìºë¦­í„° ìŠ¤íƒ€ì¼
â€¢ ğŸ  "ì£¼ì¸ë‹˜"ì„ ìœ„í•œ ì¶©ì‹¤í•œ ì„œë¹„ìŠ¤
â€¢ ğŸ”® ë§ˆë²•ê°™ì€ AI ëŠ¥ë ¥ (Google Imagen 4.0 + Claude 3.5)
â€¢ ğŸ“š ë˜‘ë˜‘í•œ ëŒ€í™” ìš”ì•½ (ê°œì¸ë³„ ë§ì¶¤)

ğŸ¯ **ë„ë¹„ëŠ” ì–¸ì œë‚˜ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!**
"ë„ë¹„ì•¼"ë¼ê³  ë¶ˆëŸ¬ì£¼ì‹œë©´ ì¦‰ì‹œ ë‹¬ë ¤ê°‘ë‹ˆë‹¤! ğŸƒâ€â™‚ï¸âœ¨`;
  } catch (error) {
    console.error('Error getting help message:', error);
    // Fallback to basic message
    return `ğŸ§™â€â™€ï¸ **ë„ë¹„ AI ë´‡ì…ë‹ˆë‹¤!** ğŸ 

ğŸ¤– **ë„ë¹„ ë´‡ v1.0.0** (ê°œë°œ ì¤‘)

ğŸŒŸ **ë„ë¹„ ê°œì¸ë¹„ì„œ ëª¨ë“œ:**
â€¢ ğŸ¨ **"ë„ë¹„ì•¼, ~~~ ê·¸ë ¤ì¤˜"** - ë§ˆë²•ê°™ì€ ì´ë¯¸ì§€ ìƒì„±
â€¢ ğŸ’¬ **"ë„ë¹„ì•¼, ~~~ ì•Œë ¤ì¤˜/ë­ì•¼?"** - ì¶©ì‹¤í•œ ì§ˆë¬¸ ë‹µë³€
â€¢ ğŸ–¼ï¸ **ì‚¬ì§„ì— ë‹µì¥** - ì´ë¯¸ì§€ í¸ì§‘ ë° ìˆ˜ì •

ğŸ“ **ëŒ€í™” ì¶”ì  ë° ìš”ì•½ ê¸°ëŠ¥:**
â€¢ **"ë„ë¹„ì•¼, ëŒ€í™” ì¶”ì  ì‹œì‘í•´ì¤˜"** - ì¤‘ìš”í•œ ëŒ€í™” ê¸°ë¡ ì‹œì‘
â€¢ **"ë„ë¹„ì•¼, ëŒ€í™” ì¶”ì  ê·¸ë§Œí•´ì¤˜"** - ì¶”ì  ì¤‘ë‹¨
â€¢ **"ë„ë¹„ì•¼, ìš”ì•½í•´ì¤˜"** - ì¶”ì ëœ ëŒ€í™”ë¥¼ ë˜‘ë˜‘í•˜ê²Œ ìš”ì•½

ğŸ¯ **ë„ë¹„ëŠ” ì–¸ì œë‚˜ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!**
"ë„ë¹„ì•¼"ë¼ê³  ë¶ˆëŸ¬ì£¼ì‹œë©´ ì¦‰ì‹œ ë‹¬ë ¤ê°‘ë‹ˆë‹¤! ğŸƒâ€â™‚ï¸âœ¨`;
  }
}

// =============================================================================
// ğŸ“¸ PHOTO UPLOAD HANDLER - New Photo Editing Flow
// =============================================================================

bot.on('message:photo', async (ctx) => {
  try {
    console.log('ğŸ“¸ Photo received from user');

    // Handle photo upload
    const uploadResult = await handlePhotoUpload(ctx);

    if (!uploadResult.success) {
      await ctx.reply(`âŒ ì‚¬ì§„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n${uploadResult.error}`);
      return;
    }

    console.log('âœ… Photo processed successfully:', uploadResult.imageUrl);

    // Build message with analysis and recommendations
    let message = `âœ… **ì‚¬ì§„ì„ ë°›ì•˜ì–´ìš”!**\n\n`;
    message += `ğŸ” **ë¶„ì„ ê²°ê³¼:**\n${uploadResult.analysisSummary || 'ë¶„ì„ ì¤‘...'}\n\n`;
    message += `â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n`;

    // Add recommendations with inline buttons
    if (uploadResult.recommendations && uploadResult.recommendations.length > 0) {
      message += `ğŸ¯ **ì¶”ì²œ ìŠ¤íƒ€ì¼** (ì í•©ë„ ìˆœ):\n\n`;

      uploadResult.recommendations.slice(0, 4).forEach((rec, index) => {
        const stars = 'â­'.repeat(Math.ceil(rec.confidence / 25));
        message += `${rec.emoji} **${rec.nameKo}** ${stars}\n`;
        message += `   â†³ ${rec.reason} (${rec.confidence}%)\n\n`;
      });

      message += `\nğŸ’¡ **ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•˜ì„¸ìš”:**\n`;

      // Store file ID in cache with short key
      const fileKey = storeFileId(ctx.chat!.id, ctx.message!.message_id, uploadResult.fileId!);

      // Create inline keyboard with template buttons
      const keyboard = new InlineKeyboard();

      uploadResult.recommendations.slice(0, 4).forEach(rec => {
        keyboard.text(
          `${rec.emoji} ${rec.nameKo}`,
          `t:${rec.templateKey}:${fileKey}`
        ).row();
      });

      // Add "View All" button
      keyboard.text('ğŸ” ì „ì²´ 38ê°œ ìŠ¤íƒ€ì¼ ë³´ê¸°', `t:all:${fileKey}`);

      await ctx.reply(message, {
        parse_mode: 'Markdown',
        reply_markup: keyboard
      });
    } else {
      message += `ğŸ“¸ **í¸ì§‘ ì˜µì…˜:**\n`;
      message += `â€¢ /edit - AI ìŠ¤íƒ€ì¼ í¸ì§‘\n`;
      message += `â€¢ ë‹µì¥ìœ¼ë¡œ "ë„ë¹„ì•¼ [ìš”ì²­]" - ì§ì ‘ í¸ì§‘\n`;

      await ctx.reply(message, { parse_mode: 'Markdown' });
    }

    // TODO: Next steps
    // 1. âœ… Analyze image (DONE)
    // 2. âœ… Recommend templates (DONE)
    // 3. âœ… Show inline buttons (DONE)
    // 4. Handle button clicks (below)

  } catch (error) {
    console.error('âŒ Error in photo handler:', error);
    await ctx.reply('âŒ ì‚¬ì§„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
  }
});

// =============================================================================
// CALLBACK QUERY HANDLERS (Inline Buttons)
// =============================================================================

// In-memory storage for file IDs (session-based)
const fileIdCache = new Map<string, string>();

function storeFileId(chatId: number, messageId: number, fileId: string): string {
  const key = `${chatId}:${messageId}`;
  fileIdCache.set(key, fileId);
  return key;
}

function getFileId(key: string): string | undefined {
  return fileIdCache.get(key);
}

// Template selection callback handler
bot.callbackQuery(/^t:([^:]+):(.+):(.+)$/, async (ctx) => {
  try {
    const templateKey = ctx.match[1];
    const chatId = parseInt(ctx.match[2]);
    const messageId = parseInt(ctx.match[3]);
    const fileKey = `${chatId}:${messageId}`;

    // Try to get from cache first
    let fileId = getFileId(fileKey);

    // If not in cache, retrieve from database using message_id
    if (!fileId) {
      console.log(`ğŸ” FileId not in cache, retrieving from database for message ${messageId}...`);

      const { data, error } = await supabase
        .from('image_analysis_results')
        .select('analysis_data')
        .eq('message_id', messageId)
        .single();

      if (error || !data) {
        await ctx.answerCallbackQuery('ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì§„ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.');
        return;
      }

      fileId = data.analysis_data?.file_id;

      if (!fileId) {
        await ctx.answerCallbackQuery('íŒŒì¼ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì§„ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.');
        return;
      }

      // Store in cache for future use
      storeFileId(chatId, messageId, fileId);
      console.log(`âœ… FileId retrieved from database and cached: ${fileId}`);
    }

    console.log(`ğŸ¨ Template selected: ${templateKey} for file: ${fileId}`);

    // Answer callback to remove loading state
    await ctx.answerCallbackQuery();

    // Handle "View All" button
    if (templateKey === 'all') {
      // Fetch all templates from database
      const { data: allTemplates, error } = await supabase
        .from('prompt_templates')
        .select('*')
        .eq('is_active', true)
        .order('priority', { ascending: false });

      if (error || !allTemplates) {
        await ctx.reply('âŒ í…œí”Œë¦¿ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
        return;
      }

      // Create paginated keyboard with all templates (8 per page)
      const keyboard = new InlineKeyboard();
      const templatesPerPage = 8;
      const templates = allTemplates.slice(0, templatesPerPage);

      templates.forEach(template => {
        const emoji = getCategoryEmoji(template.category);
        keyboard.text(
          `${emoji} ${template.template_name_ko}`,
          `t:${template.template_key}:${fileKey}`
        ).row();
      });

      // Add pagination if more than 8 templates
      if (allTemplates.length > templatesPerPage) {
        keyboard.text('â¡ï¸ ë‹¤ìŒ í˜ì´ì§€', `tp:1:${fileKey}`);
      }

      await ctx.reply('ğŸ¨ **ì „ì²´ ìŠ¤íƒ€ì¼ ëª©ë¡:**\n\nì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ì„ íƒí•˜ì„¸ìš”:', {
        reply_markup: keyboard
      });
      return;
    }

    // Fetch selected template from database
    const { data: template, error } = await supabase
      .from('prompt_templates')
      .select('*')
      .eq('template_key', templateKey)
      .single();

    if (error || !template) {
      await ctx.reply('âŒ ì„ íƒí•œ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    // Get image URL from fileId
    const file = await ctx.api.getFile(fileId);
    if (!file.file_path) {
      await ctx.reply('âŒ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    const imageUrl = `https://api.telegram.org/file/bot${BOT_TOKEN}/${file.file_path}`;

    // Send processing message
    const processingMsg = await ctx.reply(
      `âœ¨ **${template.template_name_ko}** ìŠ¤íƒ€ì¼ë¡œ í¸ì§‘ ì¤‘...\n\n` +
      `ğŸ¨ AIê°€ ì‘ì—… ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...`
    );

    console.log('ğŸ“‹ Template details:', {
      name: template.template_name_ko,
      category: template.category,
      prompt: template.base_prompt.substring(0, 100) + '...'
    });

    // Execute image editing with Replicate
    const { editImageWithReplicate } = await import('../../src/services/image-edit-service');

    const editResult = await editImageWithReplicate({
      imageUrl,
      templatePrompt: template.base_prompt,
      templateName: template.template_name_ko,
      category: template.category
    });

    if (editResult.success && editResult.outputUrl) {
      // Update processing message
      await ctx.api.editMessageText(
        ctx.chat!.id,
        processingMsg.message_id,
        `âœ… **í¸ì§‘ ì™„ë£Œ!**\n\n` +
        `ğŸ¨ ìŠ¤íƒ€ì¼: ${template.template_name_ko}\n` +
        `â±ï¸ ì²˜ë¦¬ ì‹œê°„: ${Math.round(editResult.processingTime! / 1000)}ì´ˆ\n\n` +
        `ê²°ê³¼ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤...`
      );

      // Create action buttons for the edited image
      const actionKeyboard = new InlineKeyboard()
        .text('ğŸ”„ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì‹œë„', `retry:${fileKey}`)
        .text('ğŸ’¾ ì›ë³¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°', `back:${fileKey}`).row()
        .text('ğŸ¨ ë‹¤ì‹œ í¸ì§‘', `redo:${template.template_key}:${fileKey}`)
        .text('â­ ì´ ìŠ¤íƒ€ì¼ í‰ê°€', `rate:${template.template_key}`);

      // Send edited image with action buttons
      await ctx.replyWithPhoto(editResult.outputUrl, {
        caption: `âœ¨ **${template.template_name_ko}** ìŠ¤íƒ€ì¼ í¸ì§‘ ì™„ë£Œ!\n\n` +
          `ğŸ“ í”„ë¡¬í”„íŠ¸: ${template.base_prompt.substring(0, 100)}...\n` +
          `â±ï¸ ${Math.round(editResult.processingTime! / 1000)}ì´ˆ ì†Œìš”\n\n` +
          `ğŸ’¡ **ë‹¤ìŒ ì•¡ì…˜:**\n` +
          `â€¢ ğŸ”„ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”\n` +
          `â€¢ ğŸ’¾ ì›ë³¸ ì´ë¯¸ì§€ë¡œ ëŒì•„ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n` +
          `â€¢ ğŸ¨ ê°™ì€ ìŠ¤íƒ€ì¼ë¡œ ë‹¤ì‹œ í¸ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤`,
        reply_markup: actionKeyboard
      });

      // Store edit result in database
      const { data: editRecord } = await supabase
        .from('image_edit_results')
        .insert({
          user_id: ctx.from?.id,
          chat_id: ctx.chat?.id,
          template_key: template.template_key,
          original_image_url: imageUrl,
          edited_image_url: editResult.outputUrl,
          processing_time_ms: editResult.processingTime,
          status: 'completed'
        })
        .select()
        .single();

      console.log('âœ… Edit result stored in database:', editRecord?.id);

    } else {
      // Handle error
      const errorMsg = editResult.error || 'Unknown error';

      await ctx.api.editMessageText(
        ctx.chat!.id,
        processingMsg.message_id,
        `âŒ **í¸ì§‘ ì‹¤íŒ¨**\n\n` +
        `ì˜¤ë¥˜: ${errorMsg}\n\n` +
        `ğŸ’¡ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ì„ ì‹œë„í•˜ê±°ë‚˜ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`
      );

      console.error('âŒ Edit failed:', errorMsg);
    }

  } catch (error) {
    console.error('âŒ Error in template callback:', error);
    await ctx.reply('âŒ í…œí”Œë¦¿ ì„ íƒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
  }
});

// Action button handlers for edited images

// Retry edit with different style
bot.callbackQuery(/^retry:(.+):(.+)$/, async (ctx) => {
  try {
    const chatId = parseInt(ctx.match[1]);
    const messageId = parseInt(ctx.match[2]);
    const fileKey = `${chatId}:${messageId}`;

    let fileId = getFileId(fileKey);

    if (!fileId) {
      const { data } = await supabase
        .from('image_analysis_results')
        .select('analysis_data')
        .eq('message_id', messageId)
        .single();

      fileId = data?.analysis_data?.file_id;
      if (fileId) storeFileId(chatId, messageId, fileId);
    }

    if (!fileId) {
      await ctx.answerCallbackQuery('ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
      return;
    }

    await ctx.answerCallbackQuery();

    // Get file and analysis
    const file = await ctx.api.getFile(fileId);
    if (!file.file_path) {
      await ctx.reply('âŒ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    const imageUrl = `https://api.telegram.org/file/bot${BOT_TOKEN}/${file.file_path}`;

    // Re-run analysis and show recommendations
    const { analyzeImage } = await import('../../src/services/image-analysis-service');
    const { getTemplateRecommendations } = await import('../../src/services/template-recommendation-service');

    const analysis = await analyzeImage(imageUrl);
    const recommendations = await getTemplateRecommendations(analysis, 5);

    // Show new recommendations
    let message = `ğŸ”„ **ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì¶”ì²œ**\n\n`;
    const keyboard = new InlineKeyboard();

    recommendations.slice(0, 4).forEach(rec => {
      message += `${rec.emoji} ${rec.nameKo} (${rec.confidence}%)\n`;
      keyboard.text(
        `${rec.emoji} ${rec.nameKo}`,
        `t:${rec.templateKey}:${fileKey}`
      ).row();
    });

    keyboard.text('ğŸ” ì „ì²´ 38ê°œ ìŠ¤íƒ€ì¼ ë³´ê¸°', `t:all:${fileKey}`);

    await ctx.reply(message, { reply_markup: keyboard });

  } catch (error) {
    console.error('âŒ Error in retry_edit:', error);
    await ctx.reply('âŒ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
  }
});

// Back to original image
bot.callbackQuery(/^back:(.+):(.+)$/, async (ctx) => {
  try {
    const chatId = parseInt(ctx.match[1]);
    const messageId = parseInt(ctx.match[2]);
    const fileKey = `${chatId}:${messageId}`;

    let fileId = getFileId(fileKey);

    if (!fileId) {
      const { data } = await supabase
        .from('image_analysis_results')
        .select('analysis_data')
        .eq('message_id', messageId)
        .single();

      fileId = data?.analysis_data?.file_id;
      if (fileId) storeFileId(chatId, messageId, fileId);
    }

    if (!fileId) {
      await ctx.answerCallbackQuery('ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
      return;
    }

    await ctx.answerCallbackQuery('ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì „ì†¡í•©ë‹ˆë‹¤...');

    const file = await ctx.api.getFile(fileId);
    if (!file.file_path) {
      await ctx.reply('âŒ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    const imageUrl = `https://api.telegram.org/file/bot${BOT_TOKEN}/${file.file_path}`;

    await ctx.replyWithPhoto(imageUrl, {
      caption: 'ğŸ“¸ **ì›ë³¸ ì´ë¯¸ì§€**\n\në‹¤ì‹œ í¸ì§‘í•˜ì‹œë ¤ë©´ ìœ„ì˜ ì¶”ì²œ ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.'
    });

  } catch (error) {
    console.error('âŒ Error in back_to_original:', error);
    await ctx.reply('âŒ ì›ë³¸ ì´ë¯¸ì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
  }
});

// Re-edit with same style
bot.callbackQuery(/^redo:([^:]+):(.+):(.+)$/, async (ctx) => {
  try {
    const templateKey = ctx.match[1];
    const chatId = parseInt(ctx.match[2]);
    const messageId = parseInt(ctx.match[3]);
    const fileKey = `${chatId}:${messageId}`;

    let fileId = getFileId(fileKey);

    if (!fileId) {
      const { data } = await supabase
        .from('image_analysis_results')
        .select('analysis_data')
        .eq('message_id', messageId)
        .single();

      fileId = data?.analysis_data?.file_id;
      if (fileId) storeFileId(chatId, messageId, fileId);
    }

    if (!fileId) {
      await ctx.answerCallbackQuery('ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
      return;
    }

    await ctx.answerCallbackQuery('ê°™ì€ ìŠ¤íƒ€ì¼ë¡œ ë‹¤ì‹œ í¸ì§‘í•©ë‹ˆë‹¤...');

    // Fetch template
    const { data: template, error } = await supabase
      .from('prompt_templates')
      .select('*')
      .eq('template_key', templateKey)
      .single();

    if (error || !template) {
      await ctx.reply('âŒ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    // Get image URL
    const file = await ctx.api.getFile(fileId);
    if (!file.file_path) {
      await ctx.reply('âŒ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    const imageUrl = `https://api.telegram.org/file/bot${BOT_TOKEN}/${file.file_path}`;

    // Execute editing (same logic as template selection)
    const processingMsg = await ctx.reply(
      `ğŸ¨ **${template.template_name_ko}** ìŠ¤íƒ€ì¼ë¡œ ë‹¤ì‹œ í¸ì§‘ ì¤‘...\n\n` +
      `âš¡ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...`
    );

    const { editImageWithReplicate } = await import('../../src/services/image-edit-service');

    const editResult = await editImageWithReplicate({
      imageUrl,
      templatePrompt: template.base_prompt,
      templateName: template.template_name_ko,
      category: template.category
    });

    if (editResult.success && editResult.outputUrl) {
      await ctx.api.editMessageText(
        ctx.chat!.id,
        processingMsg.message_id,
        `âœ… í¸ì§‘ ì™„ë£Œ!`
      );

      const actionKeyboard = new InlineKeyboard()
        .text('ğŸ”„ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì‹œë„', `retry:${fileKey}`)
        .text('ğŸ’¾ ì›ë³¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°', `back:${fileKey}`).row()
        .text('ğŸ¨ ë‹¤ì‹œ í¸ì§‘', `redo:${template.template_key}:${fileKey}`)
        .text('â­ ì´ ìŠ¤íƒ€ì¼ í‰ê°€', `rate:${template.template_key}`);

      await ctx.replyWithPhoto(editResult.outputUrl, {
        caption: `âœ¨ **${template.template_name_ko}** ì¬í¸ì§‘ ì™„ë£Œ!`,
        reply_markup: actionKeyboard
      });
    } else {
      await ctx.api.editMessageText(
        ctx.chat!.id,
        processingMsg.message_id,
        `âŒ í¸ì§‘ ì‹¤íŒ¨: ${editResult.error}`
      );
    }

  } catch (error) {
    console.error('âŒ Error in re_edit:', error);
    await ctx.reply('âŒ ì¬í¸ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
  }
});

// Rate style
bot.callbackQuery(/^rate:(.+)$/, async (ctx) => {
  try {
    const templateKey = ctx.match[1];
    await ctx.answerCallbackQuery();

    const ratingKeyboard = new InlineKeyboard()
      .text('â­ 1ì ', `rating:${templateKey}:1`)
      .text('â­â­ 2ì ', `rating:${templateKey}:2`)
      .text('â­â­â­ 3ì ', `rating:${templateKey}:3`).row()
      .text('â­â­â­â­ 4ì ', `rating:${templateKey}:4`)
      .text('â­â­â­â­â­ 5ì ', `rating:${templateKey}:5`);

    await ctx.reply('â­ **ì´ ìŠ¤íƒ€ì¼ì„ í‰ê°€í•´ì£¼ì„¸ìš”:**\n\në³„ì ì„ ì„ íƒí•˜ì„¸ìš”:', {
      reply_markup: ratingKeyboard
    });

  } catch (error) {
    console.error('âŒ Error in rate_style:', error);
    await ctx.reply('âŒ í‰ê°€ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
  }
});

// Submit rating
bot.callbackQuery(/^rating:(.+):(\d+)$/, async (ctx) => {
  try {
    const templateKey = ctx.match[1];
    const rating = parseInt(ctx.match[2]);

    await ctx.answerCallbackQuery(`${rating}ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! â­`);

    // Store rating (optional - can add rating table later)
    console.log(`ğŸ“Š User ${ctx.from?.id} rated ${templateKey}: ${rating} stars`);

    await ctx.reply(`âœ… **í‰ê°€ ì™„ë£Œ!**\n\n${templateKey} ìŠ¤íƒ€ì¼ì— ${rating}ì ì„ ì£¼ì…¨ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ™`);

  } catch (error) {
    console.error('âŒ Error in submit_rating:', error);
  }
});

// Helper function to get category emoji
function getCategoryEmoji(category: string): string {
  const emojiMap: Record<string, string> = {
    '3d_figurine': 'ğŸ­',
    'portrait_styling': 'ğŸ“¸',
    'game_animation': 'ğŸ®',
    'image_editing': 'ğŸ› ï¸',
    'creative_transform': 'âœ¨'
  };
  return emojiMap[category] || 'ğŸ¨';
}

// Bot commands
bot.command('start', async (ctx) => {
  console.log('ğŸ“¨ Start command received');
  const helpMessage = await getHelpMessage();
  await ctx.reply(helpMessage);
});

// Help command - shows same content as start
bot.command('help', async (ctx) => {
  console.log('â“ Help command received');
  const helpMessage = await getHelpMessage();
  await ctx.reply(helpMessage);
});

// Version command - shows version history
bot.command('version', async (ctx) => {
  console.log('ğŸ“š Version command received');

  try {
    const versionHistory = await getFormattedVersionHistory(5);
    await ctx.reply(`${versionHistory}

ğŸ’¡ **ëª…ë ¹ì–´:**
â€¢ /version - ìµœê·¼ 5ê°œ ë²„ì „ ë³´ê¸°
â€¢ /help - ì‚¬ìš©ë²• ë³´ê¸°

ğŸ  ë„ë¹„ê°€ ì§€ì†ì ìœ¼ë¡œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤!`);

  } catch (error) {
    console.error('Error fetching version history:', error);
    await ctx.reply(`âŒ **ë²„ì „ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤**

${(error as Error).message}

ğŸ’¡ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`);
  }
});

bot.command('test', async (ctx) => {
  console.log('ğŸ§ª Test command received');
  await ctx.reply(`ğŸ§ª í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ ì„±ê³µ!

ğŸŒ ë°°í¬ í™˜ê²½:
â€¢ í”Œë«í¼: âœ… Netlify Functions
â€¢ í†µì‹  ë°©ì‹: âœ… Webhook (ì‹¤ì‹œê°„)
â€¢ Claude API: âœ… ${CLAUDE_API_KEY ? 'ì—°ê²°ë¨' : 'âŒ ë¯¸ì—°ê²°'}
â€¢ Google Imagen: âœ… ${GOOGLE_API_KEY ? 'ì—°ê²°ë¨' : 'âŒ ë¯¸ì—°ê²°'}

â° ì„œë²„ ì‹œê°„: ${new Date().toISOString()}
ğŸŒ í•­ìƒ ì˜¨ë¼ì¸ ìƒíƒœë¡œ ìš´ì˜ë©ë‹ˆë‹¤!`);
});

bot.command('summary', async (ctx) => {
  console.log('ğŸ“ Summary command received');
  try {
    const claudeResponse = await callClaudeAPI('ì•ˆë…•í•˜ì„¸ìš”! í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì§§ê²Œ ì¸ì‚¬í•´ì£¼ì„¸ìš”.');
    await ctx.reply(`ğŸ‰ Claude API í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ ì„±ê³µ!

Claudeì˜ ì‘ë‹µ:
${claudeResponse.text}

ğŸ’° ë¹„ìš©: ${formatCost(claudeResponse.cost)}
â±ï¸ ì²˜ë¦¬ì‹œê°„: ${claudeResponse.processingTime}ms
ğŸ”¤ í† í° ì‚¬ìš©ëŸ‰: ${claudeResponse.inputTokens} â†’ ${claudeResponse.outputTokens}

âœ… ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì—ì„œ AI ì—°ë™ ì™„ë£Œ!`);

  } catch (error) {
    await handleError(ctx, error as Error, 'Claude API í…ŒìŠ¤íŠ¸');
  }
});

bot.command('image', async (ctx) => {
  const prompt = ctx.message?.text?.replace('/image', '').trim() || '';
  if (!prompt) {
    await ctx.reply(`ğŸ¨ **ì´ë¯¸ì§€ ìƒì„± ì‚¬ìš©ë²•:**\n\n/image [ìƒì„¸í•œ ì„¤ëª…]\n\nì˜ˆì‹œ:\nâ€¢ /image ë¯¸ë˜ì ì¸ ë¡œë´‡ ê°œë°œì`);
    return;
  }

  console.log(`ğŸ¨ Image generation requested: "${prompt}"`);
  const generatingMessage = await ctx.reply(`ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\n\ní”„ë¡¬í”„íŠ¸: "${prompt}"`);

  try {
    const imageResult = await generateImageWithImagen(prompt, false, ctx.from?.id?.toString(), ctx.chat?.id?.toString());

    // Create buffer from base64

    const imageBuffer = Buffer.from(imageResult.imageData.replace(/^data:image\/[a-z]+;base64,/, ''), 'base64');

    await ctx.replyWithPhoto(new InputFile(imageBuffer, `generated_${Date.now()}.png`), {
      caption: `ğŸ¨ í”„ë¡œë•ì…˜ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!

í”„ë¡¬í”„íŠ¸: "${prompt}"

âœ¨ Google Imagen 4.0
ğŸŒ Netlify Functions
ğŸ¯ í•´ìƒë„: 1024x1024
ğŸ’° ë¹„ìš©: ${formatCost(imageResult.cost)}
â±ï¸ ì²˜ë¦¬ì‹œê°„: ${imageResult.processingTime}ms
ğŸ“… ${new Date().toLocaleString('ko-KR')}`

    });

    await ctx.api.deleteMessage(ctx.chat.id, generatingMessage.message_id);
    console.log('âœ… Image sent successfully!');
  } catch (error) {
    await handleError(ctx, error as Error, 'ì´ë¯¸ì§€ ìƒì„±', generatingMessage);
  }
});

// Generate command for image creation (also used for 2-stage editing)
bot.command('generate', async (ctx) => {
  const prompt = ctx.message?.text?.replace('/generate', '').trim() || '';

  if (!prompt) {
    await ctx.reply(`ğŸ¨ **ì´ë¯¸ì§€ ìƒì„± ì‚¬ìš©ë²•:**

/generate [í”„ë¡¬í”„íŠ¸]

ì˜ˆì‹œ:
â€¢ /generate ê·€ì—¬ìš´ ê°•ì•„ì§€ê°€ ê³µì›ì—ì„œ ë…¸ëŠ” ëª¨ìŠµ
â€¢ /generate futuristic city with flying cars
â€¢ /generate ì•„ë¦„ë‹¤ìš´ ì¼ëª°ì´ ìˆëŠ” í•´ë³€

ğŸ’¡ **ì´ë¯¸ì§€ í¸ì§‘ í›„ ì‚¬ìš©:**
ì´ë¯¸ì§€ ë¶„ì„ í›„ ì œê³µëœ í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„± ê°€ëŠ¥`);
    return;
  }

  console.log(`ğŸ¨ Generating image with prompt: "${prompt}"`);
  const generatingMessage = await ctx.reply(`ğŸ¨ **ì´ë¯¸ì§€ ìƒì„± ì¤‘...**

ğŸ“ í”„ë¡¬í”„íŠ¸: "${prompt}"
ğŸ¤– AI: Google Imagen 4.0
âš¡ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...`);

  try {
    const imageResult = await generateImageWithImagen(prompt, false, ctx.from?.id?.toString(), ctx.chat?.id?.toString());

    // Create buffer from base64
    const imageBuffer = Buffer.from(imageResult.imageData.replace(/^data:image\/[a-z]+;base64,/, ''), 'base64');

    await ctx.replyWithPhoto(new InputFile(imageBuffer, `generated_${Date.now()}.png`), {
      caption: `ğŸ¨ **ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!**

ğŸ“ **í”„ë¡¬í”„íŠ¸**: "${prompt}"
âœ¨ **AI**: Google Imagen 4.0
ğŸ’° **ë¹„ìš©**: ${formatCost(imageResult.cost)}
â±ï¸ **ì²˜ë¦¬ì‹œê°„**: ${imageResult.processingTime}ms

ğŸ“… ${new Date().toLocaleString('ko-KR')}`
    });

    await ctx.api.deleteMessage(ctx.chat.id, generatingMessage.message_id);
    console.log('âœ… Image sent successfully!');

  } catch (error) {
    await handleError(ctx, error as Error, 'ì´ë¯¸ì§€ ìƒì„±', generatingMessage);
  }
});

// NSFW Image Generation with Replicate
bot.command('nsfw_imagine', async (ctx) => {
  const prompt = ctx.message?.text?.replace('/nsfw_imagine', '').trim() || '';

  if (!prompt) {
    await ctx.reply(`ğŸ” **NSFW ì´ë¯¸ì§€ ìƒì„± ì‚¬ìš©ë²•:**

/nsfw_imagine [í”„ë¡¬í”„íŠ¸]

âš ï¸ **ì£¼ì˜ì‚¬í•­:**
â€¢ ì„±ì¸ìš© ì½˜í…ì¸  ìƒì„± ê¸°ëŠ¥ì…ë‹ˆë‹¤
â€¢ ì¼ì¼ 5íšŒ ì œí•œ
â€¢ 20 í† í° ì†Œëª¨
â€¢ ì²˜ë¦¬ ì‹œê°„: ì•½ 30-60ì´ˆ

ğŸ’¡ **ì˜ˆì‹œ:**
â€¢ /nsfw_imagine beautiful woman in elegant dress
â€¢ /nsfw_imagine artistic portrait photography

ğŸ¤– **AI**: Flux.1Dev Uncensored (MSFLUX NSFW v3)`);
    return;
  }

  if (!replicateService.isAvailable()) {
    await ctx.reply(`âŒ **NSFW ìƒì„± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.**

ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.`);
    return;
  }

  console.log(`ğŸ” NSFW image generation requested: "${prompt}"`);

  try {
    // Check daily limit - DISABLED FOR TESTING
    // const { data: limitCheck } = await supabase.rpc('check_nsfw_daily_limit', {
    //   p_user_id: ctx.from!.id
    // });

    // if (!limitCheck) {
    //   await ctx.reply(`âŒ **ì¼ì¼ ìƒì„± ì œí•œ ì´ˆê³¼**

    // ì˜¤ëŠ˜ì€ ì´ë¯¸ 5íšŒì˜ NSFW ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì…¨ìŠµë‹ˆë‹¤.
    // ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`);
    //   return;
    // }

    const generatingMessage = await ctx.reply(`ğŸ” **NSFW ì´ë¯¸ì§€ ìƒì„± ì¤‘...**

ğŸ“ í”„ë¡¬í”„íŠ¸: "${prompt}"
ğŸ¤– AI: Flux.1Dev Uncensored
â³ ì•½ 30-60ì´ˆ ì†Œìš”ë©ë‹ˆë‹¤...

ğŸ”” ì™„ë£Œë˜ë©´ ì•Œë¦¼ì„ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.`);

    // Create database record
    const { data: generation, error: dbError } = await supabase
      .from('nsfw_generations')
      .insert({
        user_id: ctx.from!.id,
        chat_id: ctx.chat!.id,
        type: 'image',
        prompt: prompt,
        model_version: 'flux-1dev-uncensored',
        status: 'processing'
      })
      .select()
      .single();

    if (dbError) {
      console.error('âŒ Failed to create generation record:', dbError);
      await ctx.api.editMessageText(
        ctx.chat!.id,
        generatingMessage.message_id,
        'âŒ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      );
      return;
    }

    // Generate image
    const imageUrls = await replicateService.generateNSFWImage(prompt);

    // Update database
    await supabase
      .from('nsfw_generations')
      .update({
        status: 'completed',
        output_url: imageUrls[0],
        completed_at: new Date().toISOString()
      })
      .eq('id', generation.id);

    // Delete processing message
    await ctx.api.deleteMessage(ctx.chat!.id, generatingMessage.message_id);

    // Send result
    for (const url of imageUrls) {
      await ctx.replyWithPhoto(url, {
        caption: imageUrls.length === 1 ? `âœ¨ **NSFW ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!**

ğŸ“ í”„ë¡¬í”„íŠ¸: "${prompt}"
ğŸ¤– AI: Flux.1Dev Uncensored (MSFLUX NSFW v3)
ğŸ’° ë¹„ìš©: 20 í† í°

ğŸ” ì„±ì¸ìš© ì½˜í…ì¸ ì…ë‹ˆë‹¤.` : undefined
      });
    }

    console.log('âœ… NSFW image generated successfully!');

  } catch (error) {
    console.error('âŒ NSFW image generation error:', error);

    // Extract meaningful error message
    let errorMsg = 'Unknown error';
    if (error instanceof Error) {
      if (error.message.includes('403')) {
        errorMsg = 'API ì ‘ê·¼ ê±°ë¶€ (403). Replicate ê³„ì • ë˜ëŠ” í† í°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
      } else if (error.message.includes('401')) {
        errorMsg = 'API ì¸ì¦ ì‹¤íŒ¨. í† í°ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.';
      } else if (error.message.includes('429')) {
        errorMsg = 'API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
      } else {
        // Use only first 100 characters of error message
        errorMsg = error.message.substring(0, 100);
      }
    }

    await ctx.reply(`âŒ **NSFW ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨**

ì˜¤ë¥˜: ${errorMsg}

ğŸ’¡ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`);
  }
});

// NSFW Video Generation with Replicate
bot.command('nsfw_video', async (ctx) => {
  const prompt = ctx.message?.text?.replace('/nsfw_video', '').trim() || '';

  if (!prompt) {
    await ctx.reply(`ğŸ” **NSFW ë¹„ë””ì˜¤ ìƒì„± ì‚¬ìš©ë²•:**

/nsfw_video [í”„ë¡¬í”„íŠ¸]

âš ï¸ **ì£¼ì˜ì‚¬í•­:**
â€¢ ì„±ì¸ìš© ë¹„ë””ì˜¤ ìƒì„± ê¸°ëŠ¥ì…ë‹ˆë‹¤
â€¢ ì¼ì¼ 5íšŒ ì œí•œ
â€¢ 30 í† í° ì†Œëª¨
â€¢ ì²˜ë¦¬ ì‹œê°„: ì•½ 2-5ë¶„

ğŸ’¡ **ì˜ˆì‹œ:**
â€¢ /nsfw_video woman walking in the rain
â€¢ /nsfw_video dancer performing on stage

ğŸ¤– **AI**: Zeroscope V2 XL (Replicate)`);
    return;
  }

  if (!replicateService.isAvailable()) {
    await ctx.reply(`âŒ **NSFW ìƒì„± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.**

ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.`);
    return;
  }

  console.log(`ğŸ” NSFW video generation requested: "${prompt}"`);

  try {
    // Check daily limit - DISABLED FOR TESTING
    // const { data: limitCheck } = await supabase.rpc('check_nsfw_daily_limit', {
    //   p_user_id: ctx.from!.id
    // });

    // if (!limitCheck) {
    //   await ctx.reply(`âŒ **ì¼ì¼ ìƒì„± ì œí•œ ì´ˆê³¼**

    // ì˜¤ëŠ˜ì€ ì´ë¯¸ 5íšŒì˜ NSFW ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì…¨ìŠµë‹ˆë‹¤.
    // ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`);
    //   return;
    // }

    const generatingMessage = await ctx.reply(`ğŸ” **NSFW ë¹„ë””ì˜¤ ìƒì„± ì¤‘...**

ğŸ“ í”„ë¡¬í”„íŠ¸: "${prompt}"
ğŸ¤– AI: Zeroscope V2 XL
â³ ì•½ 2-5ë¶„ ì†Œìš”ë©ë‹ˆë‹¤...

ğŸ”” ì™„ë£Œë˜ë©´ ì•Œë¦¼ì„ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.`);

    // Create database record
    const { data: generation, error: dbError } = await supabase
      .from('nsfw_generations')
      .insert({
        user_id: ctx.from!.id,
        chat_id: ctx.chat!.id,
        type: 'video',
        prompt: prompt,
        model_version: 'zeroscope-v2-xl',
        status: 'processing',
        tokens_used: 30
      })
      .select()
      .single();

    if (dbError) {
      console.error('âŒ Failed to create generation record:', dbError);
      await ctx.api.editMessageText(
        ctx.chat!.id,
        generatingMessage.message_id,
        'âŒ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      );
      return;
    }

    // Generate video
    const videoUrl = await replicateService.generateNSFWVideo(prompt);

    // Update database
    await supabase
      .from('nsfw_generations')
      .update({
        status: 'completed',
        output_url: videoUrl,
        completed_at: new Date().toISOString()
      })
      .eq('id', generation.id);

    // Delete processing message
    await ctx.api.deleteMessage(ctx.chat!.id, generatingMessage.message_id);

    // Send result
    await ctx.replyWithVideo(videoUrl, {
      caption: `âœ¨ **NSFW ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!**

ğŸ“ í”„ë¡¬í”„íŠ¸: "${prompt}"
ğŸ¤– AI: Zeroscope V2 XL
ğŸ’° ë¹„ìš©: 30 í† í°

ğŸ” ì„±ì¸ìš© ì½˜í…ì¸ ì…ë‹ˆë‹¤.`
    });

    console.log('âœ… NSFW video generated successfully!');

  } catch (error) {
    console.error('âŒ NSFW video generation error:', error);
    await ctx.reply(`âŒ **NSFW ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨**

ì˜¤ë¥˜: ${(error as Error).message}

ğŸ’¡ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`);
  }
});

bot.command('ask', async (ctx) => {
  const question = ctx.message?.text?.replace('/ask', '').trim() || '';
  if (!question) {
    await ctx.reply(`ğŸ¤” **AI ì§ˆë¬¸ë‹µë³€ ì‚¬ìš©ë²•:**\n\n/ask [ì§ˆë¬¸ë‚´ìš©]\n\nì˜ˆì‹œ:\nâ€¢ /ask íŒŒì´ì¬ ë¬¸ë²• ì–´ë–»ê²Œ ë°°ì›Œ?`);
    return;
  }

  console.log(`ğŸ” Explicit question asked: "${question}"`);
  const thinkingMessage = await ctx.reply(`ğŸ¤” ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n\nì§ˆë¬¸: "${question}"`);

  try {
    const answerResult = await answerQuestion(question, false, ctx.from?.id?.toString(), ctx.chat?.id?.toString());

    // Delete thinking message and send answer
    await ctx.api.deleteMessage(ctx.chat.id, thinkingMessage.message_id);

    await ctx.reply(`ğŸ¤– **AI ë‹µë³€** (/ask ëª…ë ¹ì–´)

â“ **ì§ˆë¬¸:** ${question}

ğŸ’¡ **ë‹µë³€:**
${answerResult.text}

ğŸ’° **ë¹„ìš©:** ${formatCost(answerResult.cost)}
â±ï¸ **ì²˜ë¦¬ì‹œê°„:** ${answerResult.processingTime}ms
ğŸ”¤ **í† í°:** ${answerResult.tokenUsage.input} â†’ ${answerResult.tokenUsage.output}

---
âœ¨ ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ì–¸ì œë“  /ask [ì§ˆë¬¸] í•˜ì„¸ìš”!
â° ${new Date().toLocaleString('ko-KR')}`);


    console.log('âœ… Explicit question answered successfully!');
  } catch (error) {
    await handleError(ctx, error as Error, 'ì§ˆë¬¸ ë‹µë³€', thinkingMessage);
  }
});

// Tracking Commands
bot.command('track_start', async (ctx) => {
  console.log('ğŸŸ¢ /track_start command received');
  const command = parseTrackingCommand('/track_start', ctx);
  if (command) {
    await handleTrackingCommand(command, ctx);
  }
});

bot.command('track_stop', async (ctx) => {
  console.log('ğŸ”´ /track_stop command received');
  const command = parseTrackingCommand('/track_stop', ctx);
  if (command) {
    await handleTrackingCommand(command, ctx);
  }
});

bot.command('summarize', async (ctx) => {
  console.log('ğŸ“ /summarize command received');
  const command = parseTrackingCommand('/summarize', ctx);
  if (command) {
    await handleTrackingCommand(command, ctx);
  }
});

bot.command('track_status', async (ctx) => {
  console.log('ğŸ“Š /track_status command received');
  const command = parseTrackingCommand('/track_status', ctx);
  if (command) {
    await handleTrackingCommand(command, ctx);
  }
});

// Health check and maintenance commands (admin only)
bot.command('health', async (ctx) => {
  console.log('ğŸ¥ /health command received');
  
  try {
    const { performHealthCheck } = await import('../../src/utils/error-handler');
    const health = await performHealthCheck();
    
    const statusEmoji = {
      database: health.database ? 'âœ…' : 'âŒ',
      claude_api: health.claude_api ? 'âœ…' : 'âŒ',
      tracking_system: health.tracking_system ? 'âœ…' : 'âŒ'
    };
    
    await ctx.reply(`ğŸ¥ **ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€ ê²°ê³¼**

ğŸ“Š **ì„œë¹„ìŠ¤ ìƒíƒœ:**
â€¢ ë°ì´í„°ë² ì´ìŠ¤: ${statusEmoji.database}
â€¢ Claude AI: ${statusEmoji.claude_api}  
â€¢ ì¶”ì  ì‹œìŠ¤í…œ: ${statusEmoji.tracking_system}

${health.issues.length > 0 ? `âš ï¸ **ë°œê²¬ëœ ë¬¸ì œ:**\n${health.issues.map(issue => `â€¢ ${issue}`).join('\n')}` : 'âœ… ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!'}

â° ì ê²€ ì‹œê°„: ${new Date().toLocaleString('ko-KR')}`);

  } catch (error) {
    console.error('Health check error:', error);
    await ctx.reply(`âŒ ìƒíƒœ ì ê²€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${(error as Error).message}`);
  }
});

bot.command('maintenance', async (ctx) => {
  console.log('ğŸ”§ /maintenance command received');
  
  try {
    const { recoverOrphanedSessions, performConsistencyCheck } = await import('../../src/utils/error-handler');
    
    const maintenanceMsg = await ctx.reply('ğŸ”§ **ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...**\n\nâ³ ë°ì´í„° ì •ë¦¬ ë° ë³µêµ¬ ì¤‘...');
    
    // Perform maintenance tasks
    const [recovery, consistency] = await Promise.all([
      recoverOrphanedSessions(),
      performConsistencyCheck()
    ]);
    
    await ctx.api.editMessageText(
      ctx.chat.id,
      maintenanceMsg.message_id,
      `ğŸ”§ **ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜ ì™„ë£Œ**

ğŸ“Š **ì„¸ì…˜ ë³µêµ¬:**
â€¢ ë³µêµ¬ë¨: ${recovery.recovered}ê°œ
â€¢ ë§Œë£Œë¨: ${recovery.expired}ê°œ

ğŸ” **ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬:**
â€¢ ì‚¬ìš©ì ì¶”ì  ìƒíƒœ ìˆ˜ì •: ${consistency.fixed_user_tracking}ê°œ
â€¢ ì„¸ì…˜ í†µê³„ ìˆ˜ì •: ${consistency.fixed_session_stats}ê°œ
â€¢ ì •ë¦¬ëœ ë©”ì‹œì§€: ${consistency.cleaned_messages}ê°œ

âœ… ìœ ì§€ë³´ìˆ˜ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!

â° ì™„ë£Œ ì‹œê°„: ${new Date().toLocaleString('ko-KR')}`
    );

  } catch (error) {
    console.error('Maintenance error:', error);
    await ctx.reply(`âŒ ìœ ì§€ë³´ìˆ˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${(error as Error).message}`);
  }
});

// Photo handling moved to image-edit-handler.ts for automatic AI suggestions
// Old photo handler has been completely removed to avoid conflicts
// Now all photo handling is done in image-edit-handler.ts which provides:
// - Automatic AI analysis and edit suggestions when photos are uploaded
// - Single photo: prioritizes figurine, styling, quality enhancement
// - Multiple photos: prioritizes merging, outfit swap, background replacement

// Handle ALL text messages - unified handler
bot.on('message:text', async (ctx) => {
  const text = ctx.message.text;
  const replyToMessage = ctx.message.reply_to_message;
  
  console.log(`ğŸ’¬ DEBUGGING - Message received: "${text}"`);
  console.log(`ğŸ’¬ DEBUGGING - From user: ${ctx.from?.first_name} (ID: ${ctx.from?.id})`);
  console.log(`ğŸ’¬ DEBUGGING - Is bot: ${ctx.from?.is_bot}`);
  console.log(`ğŸ’¬ DEBUGGING - Bot ID: ${ctx.me?.id}`);

  // ğŸš¨ CRITICAL: Skip if message is from the bot itself to prevent infinite loops
  if (ctx.from?.is_bot || ctx.from?.id === ctx.me?.id) {
    console.log(`ğŸ¤– Skipping bot's own message: ${text}`);
    return;
  }

  // ğŸš¨ CRITICAL: Skip if this is a command - let command handlers process them
  if (text.startsWith('/')) {
    console.log(`âš¡ Skipping command "${text}" - letting command handlers process it`);
    return;
  }

  // [REMOVED] Duplicate image editing handler - using the improved one below
  
  // Check if this is a reply to a photo with editing request
  if (replyToMessage && 'photo' in replyToMessage && replyToMessage.photo) {
    console.log('ğŸ–¼ï¸ Reply to photo detected, checking for editing request...');
    console.log('ğŸ“ Reply text:', text);
    console.log('ğŸ“· Photo count:', replyToMessage.photo.length);

    // Check for Dobby-style editing request or direct editing keywords
    const isDobbyEdit = text.includes('ë„ë¹„ì•¼');
    const editingKeywords = /(í¸ì§‘|ìˆ˜ì •|ë³´ì •|ë°”ê¿”|ë³€ê²½|ì¡°ì •|ê°œì„ |ë§Œë“¤ì–´|ì¶”ê°€|ë°°ê²½|ì˜ˆì˜ê²Œ|ë©‹ì§€ê²Œ|enhance|edit|modify|adjust|add|create|change|background)/i;

    if (isDobbyEdit || editingKeywords.test(text)) {
      console.log('âœï¸ Image editing request detected!');
      console.log('ğŸ” Is Dobby edit:', isDobbyEdit);
      console.log('ğŸ“ Edit request:', text);
      
      try {
        // Get the largest photo
        console.log('ğŸ“· Getting largest photo from message...');
        const photo = replyToMessage.photo[replyToMessage.photo.length - 1];
        console.log('ğŸ“· Photo file_id:', photo.file_id);

        console.log('ğŸ”„ Getting file info from Telegram API...');
        const file = await ctx.api.getFile(photo.file_id);
        console.log('ğŸ“ File path:', file.file_path);

        // Declare variables at the start of the try block
        let uploadedFileUri: string | null = null;
        let useFilesAPI = false;

        if (!file.file_path) {
          console.error('âŒ No file path received from Telegram');
          await ctx.reply('âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
          return;
        }

        // Extract editing intent from text (remove "ë„ë¹„ì•¼" if present)
        const editRequest = text.replace(/ë„ë¹„ì•¼[,\s]*/i, '').trim();

        // Send processing message with Dobby personality if requested
        const processingMsg = isDobbyEdit
          ? await ctx.reply(`ğŸ§™â€â™€ï¸ **ë„ë¹„ê°€ ì´ë¯¸ì§€ë¥¼ í¸ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤!**

ğŸ“¸ **ì›ë³¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘**: ë„ë¹„ê°€ ë§ˆë²•ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤...
âœï¸ **í¸ì§‘ ìš”ì²­**: "${editRequest}"
ğŸª„ **ë„ë¹„ì˜ ë§ˆë²•**: Gemini Vision + Imagen AI

âš¡ ë„ë¹„ê°€ ì—´ì‹¬íˆ ì‘ì—… ì¤‘ì…ë‹ˆë‹¤...`)
          : await ctx.reply(`ğŸ¨ **ì´ë¯¸ì§€ í¸ì§‘ ì¤‘...**

ğŸ“¸ **ì›ë³¸ ì´ë¯¸ì§€ ë¶„ì„**: ì§„í–‰ ì¤‘
âœï¸ **í¸ì§‘ ìš”ì²­**: "${editRequest}"
ğŸ¤– **AI ì²˜ë¦¬**: Gemini Vision + Imagen

âš¡ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...`);

        // Download image
        console.log('ğŸ“¥ Downloading image from Telegram...');
        const imageUrl = `https://api.telegram.org/file/bot${BOT_TOKEN}/${file.file_path}`;
        const imageResponse = await fetchWithTimeout(imageUrl, {}, 10000); // 10s timeout for download
        const imageArrayBuffer = await imageResponse.arrayBuffer();
        const imageBuffer = Buffer.from(imageArrayBuffer);
        const imageBase64 = imageBuffer.toString('base64');

        console.log('âœ… Image downloaded, size:', imageBuffer.length, 'bytes');

        // Determine if we should use Files API based on size (15MB limit for inline data)
        useFilesAPI = imageBuffer.length > FILES_API_THRESHOLD;

        console.log(`ğŸ“Š Image size analysis:`, {
          sizeBytes: imageBuffer.length,
          sizeMB: (imageBuffer.length / (1024 * 1024)).toFixed(2),
          threshold: (FILES_API_THRESHOLD / (1024 * 1024)).toFixed(0) + 'MB',
          useFilesAPI: useFilesAPI,
          method: useFilesAPI ? 'Files API (Large Image)' : 'Inline Data (Standard)'
        });

        // Use Gemini for real image editing
        console.log('ğŸ¨ Starting real image editing with Gemini...');

        const editStartTime = Date.now();
        // uploadedFileUri already declared above

        // Try multiple Gemini models for image editing
        let editResponse;
        let modelUsed = '';

        // Try Gemini 2.5 Flash Image Preview for actual image editing
        try {
          console.log('ğŸ”„ Trying Gemini 2.5 Flash Image Preview for direct image editing...');

          // Upload file if using Files API
          if (useFilesAPI && !uploadedFileUri) {
            console.log('ğŸ“¤ Uploading large image to Files API...');
            const uploadResult = await uploadToGeminiFiles(imageBuffer, 'image/jpeg');
            uploadedFileUri = uploadResult.uri;
            console.log('âœ… Image uploaded to Files API:', uploadedFileUri);
          }

          // Use Files API or inline data based on image size
          if (useFilesAPI && uploadedFileUri) {
            editResponse = await processImageWithFilesAPI(
              uploadedFileUri,
              editRequest,
              'gemini-2.5-flash-image-preview'
            );
          } else {
            editResponse = await fetchWithTimeout(
              `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image-preview:generateContent?key=${GOOGLE_API_KEY}`,
              {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                  contents: [{
                    parts: [
                      {
                        text: `Generate an edited version of this image with the following modification: ${editRequest}

                        Important: You must return the edited image itself, not a text description.
                        Apply the requested changes directly to the image while preserving the original subjects and composition.
                        Output: Modified image with the requested changes applied.`
                      },
                      {
                        inline_data: {
                          mime_type: 'image/jpeg',
                          data: imageBase64
                        }
                      }
                    ]
                  }],
                  generationConfig: {
                    temperature: 0.4,
                    maxOutputTokens: 8192
                  }
                })
              },
              30000 // 30-second timeout
            );
          }
          modelUsed = 'Gemini 2.5 Flash Image Preview' + (useFilesAPI ? ' (Files API)' : '');

          // Trust that Gemini will return an image with the improved prompt
        } catch (error) {
          console.log('âš ï¸ Gemini 2.5 Flash Image Preview failed or returned text:', error);

          // Try Gemini 2.0 Flash Experimental as second attempt
          try {
            console.log('ğŸ”„ Trying Gemini 2.0 Flash Experimental as fallback...');

            // Upload file if using Files API and not already uploaded
            if (useFilesAPI && !uploadedFileUri) {
              console.log('ğŸ“¤ Uploading large image to Files API for fallback...');
              const uploadResult = await uploadToGeminiFiles(imageBuffer, 'image/jpeg');
              uploadedFileUri = uploadResult.uri;
              console.log('âœ… Image uploaded to Files API:', uploadedFileUri);
            }

            // Use Files API or inline data based on image size
            if (useFilesAPI && uploadedFileUri) {
              editResponse = await processImageWithFilesAPI(
                uploadedFileUri,
                editRequest,
                'gemini-2.0-flash-exp'
              );
            } else {
              editResponse = await fetchWithTimeout(
                `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${GOOGLE_API_KEY}`,
                {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({
                    contents: [{
                      parts: [
                        {
                          text: `You are an image editor. Edit this image based on: "${editRequest}"

                          Modify the image to fulfill this request while maintaining the original subjects and composition.
                          Apply the specific changes requested.`
                        },
                        {
                          inline_data: {
                            mime_type: 'image/jpeg',
                            data: imageBase64
                          }
                        }
                      ]
                    }],
                    generationConfig: {
                      temperature: 0.4,
                      maxOutputTokens: 8192
                    }
                  })
                },
                25000 // 25-second timeout
              );
            }
            modelUsed = 'Gemini 2.0 Flash Experimental' + (useFilesAPI ? ' (Files API)' : '');
          } catch (exp2Error) {
            console.log('âš ï¸ Gemini 2.0 Flash Experimental also failed or returned text:', exp2Error);

          // Final Fallback: Use Gemini for analysis then Imagen for generation
          console.log('ğŸ”„ Final Fallback: Gemini analysis + Imagen generation');

          // First, analyze the image with Gemini
          // Upload file if using Files API and not already uploaded
          if (useFilesAPI && !uploadedFileUri) {
            console.log('ğŸ“¤ Uploading large image to Files API for analysis...');
            const uploadResult = await uploadToGeminiFiles(imageBuffer, 'image/jpeg');
            uploadedFileUri = uploadResult.uri;
            console.log('âœ… Image uploaded to Files API:', uploadedFileUri);
          }

          let analysisResponse;
          if (useFilesAPI && uploadedFileUri) {
            // Use Files API for analysis
            analysisResponse = await fetchWithTimeout(
              `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GOOGLE_API_KEY}`,
              {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                  contents: [{
                    parts: [
                      {
                        text: `Analyze this image and create a detailed prompt for: "${editRequest}".
                        Describe what's in the image and how to modify it according to the request.
                        Output ONLY a concise prompt for image generation.`
                      },
                      {
                        fileData: {
                          mimeType: "image/jpeg",
                          fileUri: uploadedFileUri
                        }
                      }
                    ]
                  }],
                  generationConfig: {
                    temperature: 0.3,
                    maxOutputTokens: 150
                  }
                })
              },
              10000 // 10s timeout
            );
          } else {
            // Use inline data for smaller images
            analysisResponse = await fetchWithTimeout(
              `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GOOGLE_API_KEY}`,
              {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                  contents: [{
                    parts: [
                      {
                        text: `Analyze this image and create a detailed prompt for: "${editRequest}".
                        Describe what's in the image and how to modify it according to the request.
                        Output ONLY a concise prompt for image generation.`
                      },
                      { inline_data: { mime_type: 'image/jpeg', data: imageBase64 } }
                    ]
                  }],
                  generationConfig: {
                    temperature: 0.3,
                    maxOutputTokens: 150
                  }
                })
              },
              10000 // 10s timeout
            );
          }

          if (!analysisResponse.ok) {
            throw new Error('Gemini analysis failed');
          }

          const analysisData = await analysisResponse.json();
          const editPrompt = (analysisData as any).candidates?.[0]?.content?.parts?.[0]?.text?.trim() || editRequest;

          console.log('ğŸ“ Generated edit prompt:', editPrompt);

          // Generate with Imagen 4.0 based on analysis
          editResponse = await fetchWithTimeout(
            'https://generativelanguage.googleapis.com/v1beta/models/imagen-4.0-generate-001:predict',
            {
              method: 'POST',
              headers: {
                'x-goog-api-key': GOOGLE_API_KEY,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                instances: [{
                  prompt: editPrompt + ' High quality, photorealistic, detailed.'
                }],
                parameters: {
                  sampleCount: 1,
                  sampleImageSize: '1K',
                  aspectRatio: '1:1'
                }
              })
            },
            20000 // 20s timeout
          );
          modelUsed = useFilesAPI
            ? 'Gemini Analysis (Files API) + Imagen 4.0'
            : 'Gemini Analysis (Inline) + Imagen 4.0';
          }
        } finally {
          // Clean up uploaded file if it was used
          if (uploadedFileUri) {
            // Don't await - let cleanup happen in background
            deleteGeminiFile(uploadedFileUri).catch(error => {
              console.warn('Background file cleanup failed:', error);
            });
          }
        }

        if (!editResponse.ok) {
          const errorText = await editResponse.text();
          throw new Error(`API error: ${editResponse.status} - ${errorText}`);
        }

        const editData = await editResponse.json();
        const editProcessingTime = Date.now() - editStartTime;

        console.log('ğŸ“Š Response structure:', {
          model: modelUsed,
          hasCandidates: !!(editData as any).candidates,
          candidatesCount: (editData as any).candidates?.length,
          hasPredictions: !!(editData as any).predictions,
          fullResponse: JSON.stringify(editData).substring(0, 500) // Log first 500 chars for debugging
        });

        // Check for IMAGE_SAFETY rejection
        const finishReason = (editData as any).candidates?.[0]?.finishReason;
        if (finishReason === 'IMAGE_SAFETY') {
          console.log('âš ï¸ Image editing blocked by safety filter');
          throw new Error('IMAGE_SAFETY: Content blocked by safety filters');
        }

        // Extract image data based on model
        let editedImageData;
        if (modelUsed.includes('Imagen')) {
          editedImageData = (editData as any).predictions?.[0]?.bytesBase64Encoded;
          console.log('ğŸ“¸ Imagen response - Image data found:', !!editedImageData);
        } else {
          // Gemini model response - check if it returned an image or text
          const candidates = (editData as any).candidates;
          const parts = candidates?.[0]?.content?.parts;

          console.log('ğŸ“Š Gemini response analysis:', {
            hasContent: !!candidates?.[0]?.content,
            partsCount: parts?.length,
            partsTypes: parts?.map((p: any) =>
              p.inline_data ? 'image' : p.inlineData ? 'image' : p.text ? 'text' : 'unknown'
            ),
            firstPartKeys: parts?.[0] ? Object.keys(parts[0]) : null
          });

          if (parts) {
            // Look for image data in the response (check all possible formats)
            const imagePart = parts.find((part: any) =>
              part.inline_data?.mime_type?.startsWith('image/') ||
              part.inlineData?.mimeType?.startsWith('image/') ||
              part.inline_data?.mimeType?.startsWith('image/') ||
              part.inlineData?.mime_type?.startsWith('image/')
            );

            if (imagePart) {
              // Handle multiple possible response formats
              editedImageData = imagePart.inline_data?.data ||
                               imagePart.inlineData?.data ||
                               imagePart.inline_data?.data ||
                               imagePart.inlineData?.data;
              console.log('âœ… Gemini returned edited image! Data length:', editedImageData?.length);
            } else if (parts[0]?.text) {
              // If Gemini returned only text, it didn't edit the image
              console.log('âš ï¸ Gemini returned text instead of image, using Imagen fallback');
              console.log('ğŸ“ Gemini text response:', parts[0].text.substring(0, 200));
              const prompt = parts[0].text.substring(0, 500) || editRequest;

              // Generate with Imagen
              const imagenResponse = await fetchWithTimeout(
                'https://generativelanguage.googleapis.com/v1beta/models/imagen-4.0-generate-001:predict',
                {
                  method: 'POST',
                  headers: {
                    'x-goog-api-key': GOOGLE_API_KEY,
                    'Content-Type': 'application/json',
                  },
                  body: JSON.stringify({
                    instances: [{ prompt }],
                    parameters: {
                      sampleCount: 1,
                      sampleImageSize: '1K',
                      aspectRatio: '1:1'
                    }
                  })
                },
                15000 // 15s timeout for final fallback
              );

              if (imagenResponse.ok) {
                const imagenData = await imagenResponse.json();
                editedImageData = (imagenData as any).predictions?.[0]?.bytesBase64Encoded;
                modelUsed = 'Gemini + Imagen 4.0 (Fallback)';
              }
            }
          }
        }

        if (!editedImageData) {
          throw new Error('No edited image received from API');
        }

        console.log(`âœ… Image editing completed in ${editProcessingTime}ms using ${modelUsed}`);

        // Create buffer from the edited image
        const editedImageBuffer = Buffer.from(editedImageData, 'base64');

        // Delete processing message
        await ctx.api.deleteMessage(ctx.chat.id, processingMsg.message_id);

        // Calculate cost based on method used
        const baseCost = 0.002; // Base processing cost
        const filesCost = useFilesAPI ? calculateGeminiFilesCost() : 0; // Additional Files API cost
        const estimatedCost = baseCost + filesCost;

        // Send edited image with enhanced information
        const caption = isDobbyEdit
          ? `ğŸ§™â€â™€ï¸ **ë„ë¹„ê°€ ë§ˆë²•ìœ¼ë¡œ í¸ì§‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!**

âœï¸ **ì£¼ì¸ë‹˜ì˜ ìš”ì²­**: "${editRequest}"
ğŸª„ **ë„ë¹„ì˜ ë§ˆë²• ë„êµ¬**: ${modelUsed}
ğŸ“Š **ì²˜ë¦¬ ë°©ì‹**: ${useFilesAPI ? 'Files API (ëŒ€ìš©ëŸ‰)' : 'Inline Data (í‘œì¤€)'}

ğŸ’° **ë¹„ìš©**: ${formatCost(estimatedCost)}
â±ï¸ **ì²˜ë¦¬ì‹œê°„**: ${editProcessingTime}ms

âœ¨ **ë„ë¹„ì˜ í¸ì§‘ ê²°ê³¼ì…ë‹ˆë‹¤!**

ë„ë¹„ëŠ” ì£¼ì¸ë‹˜ì´ ë§Œì¡±í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤! ğŸ§™â€â™€ï¸`
          : `ğŸ¨ **ì´ë¯¸ì§€ í¸ì§‘ ì™„ë£Œ!**

âœï¸ **í¸ì§‘ ìš”ì²­**: "${editRequest}"
ğŸ¤– **AI í¸ì§‘**: ${modelUsed}
ğŸ“Š **ì²˜ë¦¬ ë°©ì‹**: ${useFilesAPI ? 'Files API (ëŒ€ìš©ëŸ‰)' : 'Inline Data (í‘œì¤€)'}

ğŸ’° **ë¹„ìš©**: ${formatCost(estimatedCost)}
â±ï¸ **ì²˜ë¦¬ì‹œê°„**: ${editProcessingTime}ms

âœ¨ **í¸ì§‘ëœ ì´ë¯¸ì§€ì…ë‹ˆë‹¤!**`;

        await ctx.replyWithPhoto(new InputFile(editedImageBuffer), {
          caption: caption
        });

        console.log('âœ… Image editing completed and sent to user');
        
      } catch (error) {
        console.error('âŒ Image editing error:', error);

        // Check if it's a safety error
        const errorMessage = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
        const isSafetyError = errorMessage.includes('IMAGE_SAFETY');

        if (isSafetyError) {
          await ctx.reply(`âš ï¸ **ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë¨**

ìš”ì²­í•˜ì‹  í¸ì§‘ ë‚´ìš©ì´ Google AIì˜ ì•ˆì „ ì •ì±…ì— ìœ„ë°˜ë©ë‹ˆë‹¤.

ğŸ’¡ **ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”:**
- ë” ìˆœí™”ëœ í‘œí˜„ìœ¼ë¡œ ìš”ì²­í•´ì£¼ì„¸ìš”
- ì˜ˆ: "ì˜ìƒì„ ìºì£¼ì–¼í•œ ì˜·ìœ¼ë¡œ ë³€ê²½"
- ì˜ˆ: "ì˜· ìƒ‰ìƒì„ íŒŒë€ìƒ‰ìœ¼ë¡œ ë³€ê²½"

ğŸ”’ ì°¨ë‹¨ëœ ë‚´ìš©: ë…¸ì¶œì´ ë§ì€ ì˜ìƒ, ì„±ì  ì½˜í…ì¸  ë“±`);
        } else {
          await ctx.reply(`âŒ **ì´ë¯¸ì§€ í¸ì§‘ ì‹¤íŒ¨**

ì˜¤ë¥˜: ${errorMessage}

ğŸ’¡ **ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”:**
- ì´ë¯¸ì§€ì— replyë¡œ "í¸ì§‘í•´ì¤˜", "ë³´ì •í•´ì¤˜", "ê°œì„ í•´ì¤˜" ë“±ìœ¼ë¡œ ìš”ì²­
- êµ¬ì²´ì ì¸ í¸ì§‘ ë‚´ìš©ì„ ëª…ì‹œí•˜ë©´ ë” ì¢‹ìŠµë‹ˆë‹¤
- ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ëŠ” Files APIë¡œ ìë™ ì²˜ë¦¬ë©ë‹ˆë‹¤`);
        }
      }
      
      return; // Exit after handling image editing
    } else {
      console.log('ğŸ’¬ Reply to photo but no editing keywords detected');
    }
  }

  // Check for Dobby activation and other commands
  console.log(`ğŸ” DEBUGGING - Checking Dobby activation for: "${text}"`);
  const dobbyCheck = isDobbyActivated(text);
  console.log(`ğŸ” DEBUGGING - Dobby check result:`, dobbyCheck);
  
  // Check for tracking commands (Dobby-style commands)
  const trackingCommand = parseTrackingCommand(text, ctx);
  console.log(`ğŸ” DEBUGGING - Tracking command result:`, trackingCommand);
  
  // Handle tracking commands if detected
  if (trackingCommand) {
    console.log(`ğŸ¯ Tracking command detected: ${trackingCommand.type}`);
    await handleTrackingCommand(trackingCommand, ctx);
    return;
  }

  if (dobbyCheck.activated) {
    console.log(`ğŸ§™â€â™€ï¸ DEBUGGING - Dobby activated! Command: ${dobbyCheck.command}, Content: "${dobbyCheck.content}"`);

    if (dobbyCheck.command === 'image') {
      // Handle Dobby image generation
      if (!dobbyCheck.content) {
        await ctx.reply(`ğŸ§™â€â™€ï¸ **ë„ë¹„ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!**

ğŸ¨ **ì´ë¯¸ì§€ ìƒì„± ì‚¬ìš©ë²•:**
â€¢ "ë„ë¹„ì•¼, ê·€ì—¬ìš´ ê°•ì•„ì§€ ê·¸ë ¤ì¤˜"
â€¢ "ë„ë¹„ì•¼, ë¯¸ë˜ì ì¸ ë¡œë´‡ ê·¸ë ¤ì¤˜"
â€¢ "ë„ë¹„ì•¼, ì•„ë¦„ë‹¤ìš´ í’ê²½ ê·¸ë¦¼ ê·¸ë ¤ì¤˜"

âœ¨ ì–´ë–¤ ê·¸ë¦¼ì„ ê·¸ë ¤ë“œë¦´ê¹Œìš”?`);
        return;
      }

      console.log(`ğŸ¨ Dobby image generation: "${dobbyCheck.content}"`);

      // Send immediate response to prevent timeout
      const processingMsg = `ğŸ§™â€â™€ï¸ **ë„ë¹„ê°€ ê·¸ë¦¼ì„ ê·¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤!**

ğŸ¨ ì£¼ì¸ë‹˜ì˜ ìš”ì²­: "${dobbyCheck.content}"
âœ¨ ë„ë¹„ê°€ ë§ˆë²•ìœ¼ë¡œ ê·¸ë¦¼ì„ ë§Œë“¤ê³  ìˆì–´ìš”...

âš¡ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!`;

      const generatingMessage = await ctx.reply(processingMsg);

      try {
        const imageResult = await generateImageWithImagen(dobbyCheck.content, true, ctx.from?.id?.toString(), ctx.chat?.id?.toString());

        // Create buffer from base64
        const imageBuffer = Buffer.from(imageResult.imageData.replace(/^data:image\/[a-z]+;base64,/, ''), 'base64');

        // Get dynamic success message with cost information
        const successMsg = await getSystemMessage('dobby_success_image', {
          user_input: dobbyCheck.content,
          cost: formatCost(imageResult.cost),
          processing_time: imageResult.processingTime,
          timestamp: new Date().toLocaleString('ko-KR')
        });

        // Send image directly from buffer
        await ctx.replyWithPhoto(new InputFile(imageBuffer, `dobby_${Date.now()}.png`), {
          caption: `${successMsg}

ğŸ’° **ë¹„ìš©**: ${formatCost(imageResult.cost)}
â±ï¸ **ì²˜ë¦¬ì‹œê°„**: ${imageResult.processingTime}ms
ğŸ¨ **ë„êµ¬**: Google Imagen 4.0`
        });

        // Delete generating message
        await ctx.api.deleteMessage(ctx.chat.id, generatingMessage.message_id);

        console.log('âœ… Dobby image generation successful!');

      } catch (error) {
        console.error('Dobby image generation error:', error);

        await ctx.api.editMessageText(
          ctx.chat.id,
          generatingMessage.message_id,
          `ğŸ§™â€â™€ï¸ **ë„ë¹„ê°€ ì‹¤ìˆ˜í–ˆìŠµë‹ˆë‹¤...**

âŒ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: ${(error as Error).message}

ğŸ˜” ë„ë¹„ëŠ” ì‹¤íŒ¨ë¥¼ ìš©ì„œë°›ì§€ ëª»í•©ë‹ˆë‹¤...
ğŸ’¡ ì ì‹œ í›„ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œë©´ ë” ì—´ì‹¬íˆ í•˜ê² ìŠµë‹ˆë‹¤!`
        );
      }

    } else if (dobbyCheck.command === 'help') {
      // Handle Dobby help command
      console.log(`â“ Dobby help request: "${dobbyCheck.content}"`);

      try {
        const helpMessage = await getHelpMessage();
        await ctx.reply(`ğŸ§™â€â™€ï¸ **ë„ë¹„ê°€ ì‚¬ìš©ë²•ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤!**

${helpMessage}

ğŸ  ì£¼ì¸ë‹˜ì„ ìœ„í•´ ì–¸ì œë“ ì§€ ë„ì›€ì„ ë“œë¦´ ì¤€ë¹„ê°€ ë˜ì–´ìˆìŠµë‹ˆë‹¤!`);

        console.log('âœ… Dobby help message sent successfully!');

      } catch (error) {
        console.error('Dobby help error:', error);
        await ctx.reply(`ğŸ§™â€â™€ï¸ **ë„ë¹„ê°€ ì‹¤ìˆ˜í–ˆìŠµë‹ˆë‹¤...**

âŒ ë„ì›€ë§ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ğŸ’¡ /help ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì‹œê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!`);
      }

    } else if (dobbyCheck.command === 'ask') {
      // Handle Dobby Q&A
      console.log(`ğŸ¤” Dobby Q&A: "${dobbyCheck.content}"`);

      // Get dynamic processing message
      const processingMsg = await getSystemMessage('dobby_processing_qa', {
        question: dobbyCheck.content
      });
      
      const thinkingMessage = await ctx.reply(processingMsg);

      try {
        const answerResult = await answerQuestion(dobbyCheck.content, true, ctx.from?.id?.toString(), ctx.chat?.id?.toString());

        // Delete thinking message and send answer
        await ctx.api.deleteMessage(ctx.chat.id, thinkingMessage.message_id);

        // Get dynamic success message
        const successMsg = await getSystemMessage('dobby_success_qa', {
          question: dobbyCheck.content,
          answer: answerResult.text,
          cost: formatCost(answerResult.cost),
          processing_time: answerResult.processingTime,
          timestamp: new Date().toLocaleString('ko-KR')
        });

        await ctx.reply(`${successMsg}

ğŸ’° **ë¹„ìš©**: ${formatCost(answerResult.cost)}
â±ï¸ **ì²˜ë¦¬ì‹œê°„**: ${answerResult.processingTime}ms
ğŸ”¤ **í† í°**: ${answerResult.tokenUsage.input} â†’ ${answerResult.tokenUsage.output}
ğŸ§  **AI**: Claude 3.5 Sonnet`);

        console.log('âœ… Dobby Q&A successful!');

      } catch (error) {
        console.error('Dobby Q&A error:', error);

        await ctx.api.editMessageText(
          ctx.chat.id,
          thinkingMessage.message_id,
          `ğŸ§™â€â™€ï¸ **ë„ë¹„ê°€ ì‹¤ìˆ˜í–ˆìŠµë‹ˆë‹¤...**

âŒ ë‹µë³€ ì¤‘ ì˜¤ë¥˜: ${(error as Error).message}

ğŸ˜” ë„ë¹„ëŠ” ì•„ì§ ëª¨ë¥´ëŠ” ê²ƒì´ ë§ìŠµë‹ˆë‹¤...
ğŸ’¡ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ë¬¼ì–´ë´ì£¼ì‹œë©´ ë” ì—´ì‹¬íˆ í•˜ê² ìŠµë‹ˆë‹¤!`
        );
      }
    }

    return; // Dobby handled the message, skip other processing
  }

  // Do not respond to regular messages without "ë„ë¹„ì•¼" keyword
  // Only slash commands and messages with "ë„ë¹„ì•¼" should trigger responses
  console.log(`ğŸ’­ Regular message (not Dobby command): "${text}" - no response`);
});

// Register image editing handlers
registerImageEditHandlers(bot);

// Debug middleware - log ALL messages
bot.use(async (ctx, next) => {
  console.log('ğŸ” DEBUG - Message type:', ctx.message?.text ? 'text' : ctx.message?.photo ? 'photo' : 'other');
  console.log('ğŸ” DEBUG - Message content:', ctx.message?.text || '[non-text]');
  console.log('ğŸ” DEBUG - From:', ctx.from?.first_name, '(', ctx.from?.id, ')');
  await next();

});

// Error handling
bot.catch((err) => {
  console.error('Production bot error:', err);
});

// Create webhook callback
const webhookHandler = webhookCallback(bot, 'std/http');

// Netlify Functions handler
export const handler: Handler = async (event: HandlerEvent, _context: HandlerContext) => {
  console.log('ğŸŒ WEBHOOK ENTRY POINT - Received request');
  console.log('ğŸŒ Method:', event.httpMethod);
  console.log('ğŸŒ Body:', event.body);
  console.log('ğŸŒ Headers:', JSON.stringify(event.headers, null, 2));

  try {
    if (event.httpMethod !== 'POST') {
      return { statusCode: 405, body: JSON.stringify({ error: 'Method not allowed' }) };
    }

    const request = new Request('https://example.com/webhook', {
      method: 'POST',
      headers: { 'content-type': 'application/json', ...event.headers },
      body: event.body
    });

    // Process webhook normally - no timeout on Render
    const response = await webhookHandler(request);

    console.log('âœ… Webhook processed');

    return {
      statusCode: response.status,
      headers: { 'Content-Type': 'application/json' },
      body: await response.text()
    };
  } catch (error) {
    console.error('âŒ Webhook processing error:', error);
    return {
      statusCode: 200, // Return 200 to prevent Telegram retry
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ ok: true })
    };
  }
};
